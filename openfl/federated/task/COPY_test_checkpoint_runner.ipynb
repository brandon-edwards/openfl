{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom nnunet.dataset_conversion.utils import generate_dataset_json\\n\\ngenerate_dataset_json(output_file=\\'/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_raw_data/Task542_FakePostOpp/dataset.json\\', \\n                      imagesTr_dir=\\'/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_raw_data/Task542_FakePostOpp/imagesTr\\', \\n                      imagesTs_dir=None, \\n                      modalities=(\\'0000\\', \\'0001\\', \\'0002\\', \\'0003\\'),\\n                      labels={\\'0\\': \\'Background\\', \\'1\\': \\'unknown1\\', \\'2\\': \\'unknown2\\', \\'3\\': \\'unknown3\\', \\'4\\': \\'unknown4\\'}, \\n                      dataset_name=\"Brandon Fake PostOpp\", \\n                      sort_keys=True, \\n                      license=\"Sourced from BraTS22, so ...\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making the ddataset json file (commented out since I ran it)\n",
    "\"\"\"\n",
    "from nnunet.dataset_conversion.utils import generate_dataset_json\n",
    "\n",
    "generate_dataset_json(output_file='/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_raw_data/Task542_FakePostOpp/dataset.json', \n",
    "                      imagesTr_dir='/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_raw_data/Task542_FakePostOpp/imagesTr', \n",
    "                      imagesTs_dir=None, \n",
    "                      modalities=('0000', '0001', '0002', '0003'),\n",
    "                      labels={'0': 'Background', '1': 'unknown1', '2': 'unknown2', '3': 'unknown3', '4': 'unknown4'}, \n",
    "                      dataset_name=\"Brandon Fake PostOpp\", \n",
    "                      sort_keys=True, \n",
    "                      license=\"Sourced from BraTS22, so ...\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained iteration: 0\n",
      "Trained iteration: 1\n",
      "Trained iteration: 2\n",
      "Trained iteration: 3\n",
      "Trained iteration: 4\n",
      "Trained iteration: 5\n",
      "Trained iteration: 6\n",
      "Trained iteration: 7\n",
      "Trained iteration: 8\n",
      "Trained iteration: 9\n",
      "Trained iteration: 10\n",
      "Trained iteration: 11\n",
      "Trained iteration: 12\n",
      "Trained iteration: 13\n",
      "Trained iteration: 14\n",
      "Trained iteration: 15\n",
      "Trained iteration: 16\n",
      "Trained iteration: 17\n",
      "Trained iteration: 18\n",
      "Trained iteration: 19\n",
      "Trained iteration: 20\n",
      "Trained iteration: 21\n",
      "Trained iteration: 22\n",
      "Trained iteration: 23\n",
      "Trained iteration: 24\n",
      "Trained iteration: 25\n",
      "Trained iteration: 26\n",
      "Trained iteration: 27\n",
      "Trained iteration: 28\n",
      "Trained iteration: 29\n",
      "Trained iteration: 30\n",
      "Trained iteration: 31\n",
      "Trained iteration: 32\n",
      "Trained iteration: 33\n",
      "Trained iteration: 34\n",
      "Trained iteration: 35\n",
      "Trained iteration: 36\n",
      "Trained iteration: 37\n",
      "Trained iteration: 38\n",
      "Trained iteration: 39\n",
      "Trained iteration: 40\n",
      "Trained iteration: 41\n",
      "Trained iteration: 42\n",
      "Trained iteration: 43\n",
      "Trained iteration: 44\n",
      "Trained iteration: 45\n",
      "Trained iteration: 46\n",
      "Trained iteration: 47\n",
      "Trained iteration: 48\n",
      "Trained iteration: 49\n",
      "Trained iteration: 50\n",
      "Trained iteration: 51\n",
      "Trained iteration: 52\n",
      "Trained iteration: 53\n",
      "Trained iteration: 54\n",
      "Trained iteration: 55\n",
      "Trained iteration: 56\n",
      "Trained iteration: 57\n",
      "Trained iteration: 58\n",
      "Trained iteration: 59\n",
      "Trained iteration: 60\n",
      "Trained iteration: 61\n",
      "Trained iteration: 62\n",
      "Trained iteration: 63\n",
      "Trained iteration: 64\n",
      "Trained iteration: 65\n",
      "Trained iteration: 66\n",
      "Trained iteration: 67\n",
      "Trained iteration: 68\n",
      "Trained iteration: 69\n",
      "Trained iteration: 70\n",
      "Trained iteration: 71\n",
      "Trained iteration: 72\n",
      "Trained iteration: 73\n",
      "Trained iteration: 74\n",
      "Trained iteration: 75\n",
      "Trained iteration: 76\n",
      "Trained iteration: 77\n",
      "Trained iteration: 78\n",
      "Trained iteration: 79\n",
      "Trained iteration: 80\n",
      "Trained iteration: 81\n",
      "Trained iteration: 82\n",
      "Trained iteration: 83\n",
      "Trained iteration: 84\n",
      "Trained iteration: 85\n",
      "Trained iteration: 86\n",
      "Trained iteration: 87\n",
      "Trained iteration: 88\n",
      "Trained iteration: 89\n",
      "Trained iteration: 90\n",
      "Trained iteration: 91\n",
      "Trained iteration: 92\n",
      "Trained iteration: 93\n",
      "Trained iteration: 94\n",
      "Trained iteration: 95\n",
      "Trained iteration: 96\n",
      "Trained iteration: 97\n",
      "Trained iteration: 98\n",
      "Trained iteration: 99\n",
      "Trained iteration: 100\n",
      "Trained iteration: 101\n",
      "Trained iteration: 102\n",
      "Trained iteration: 103\n",
      "Trained iteration: 104\n",
      "Trained iteration: 105\n",
      "Trained iteration: 106\n",
      "Trained iteration: 107\n",
      "Trained iteration: 108\n",
      "Trained iteration: 109\n",
      "Trained iteration: 110\n",
      "Trained iteration: 111\n",
      "Trained iteration: 112\n",
      "Trained iteration: 113\n",
      "Trained iteration: 114\n",
      "Trained iteration: 115\n",
      "Trained iteration: 116\n",
      "Trained iteration: 117\n",
      "Trained iteration: 118\n",
      "Trained iteration: 119\n",
      "Trained iteration: 120\n",
      "Trained iteration: 121\n",
      "Trained iteration: 122\n",
      "Trained iteration: 123\n",
      "Trained iteration: 124\n",
      "Trained iteration: 125\n",
      "Trained iteration: 126\n",
      "Trained iteration: 127\n",
      "Trained iteration: 128\n",
      "Trained iteration: 129\n",
      "Trained iteration: 130\n",
      "Trained iteration: 131\n",
      "Trained iteration: 132\n",
      "Trained iteration: 133\n",
      "Trained iteration: 134\n",
      "Trained iteration: 135\n",
      "Trained iteration: 136\n",
      "Trained iteration: 137\n",
      "Trained iteration: 138\n",
      "Trained iteration: 139\n",
      "Trained iteration: 140\n",
      "Trained iteration: 141\n",
      "Trained iteration: 142\n",
      "Trained iteration: 143\n",
      "Trained iteration: 144\n",
      "Trained iteration: 145\n",
      "Trained iteration: 146\n",
      "Trained iteration: 147\n",
      "Trained iteration: 148\n",
      "Trained iteration: 149\n",
      "Trained iteration: 150\n",
      "Trained iteration: 151\n",
      "Trained iteration: 152\n",
      "Trained iteration: 153\n",
      "Trained iteration: 154\n",
      "Trained iteration: 155\n",
      "Trained iteration: 156\n",
      "Trained iteration: 157\n",
      "Trained iteration: 158\n",
      "Trained iteration: 159\n",
      "Trained iteration: 160\n",
      "Trained iteration: 161\n",
      "Trained iteration: 162\n",
      "Trained iteration: 163\n",
      "Trained iteration: 164\n",
      "Trained iteration: 165\n",
      "Trained iteration: 166\n",
      "Trained iteration: 167\n",
      "Trained iteration: 168\n",
      "Trained iteration: 169\n",
      "Trained iteration: 170\n",
      "Trained iteration: 171\n",
      "Trained iteration: 172\n",
      "Trained iteration: 173\n",
      "Trained iteration: 174\n",
      "Trained iteration: 175\n",
      "Trained iteration: 176\n",
      "Trained iteration: 177\n",
      "Trained iteration: 178\n",
      "Trained iteration: 179\n",
      "Trained iteration: 180\n",
      "Trained iteration: 181\n",
      "Trained iteration: 182\n",
      "Trained iteration: 183\n",
      "Trained iteration: 184\n",
      "Trained iteration: 185\n",
      "Trained iteration: 186\n",
      "Trained iteration: 187\n",
      "Trained iteration: 188\n",
      "Trained iteration: 189\n",
      "Trained iteration: 190\n",
      "Trained iteration: 191\n",
      "Trained iteration: 192\n",
      "Trained iteration: 193\n",
      "Trained iteration: 194\n",
      "Trained iteration: 195\n",
      "Trained iteration: 196\n",
      "Trained iteration: 197\n",
      "Trained iteration: 198\n",
      "Trained iteration: 199\n",
      "Trained iteration: 200\n",
      "Trained iteration: 201\n",
      "Trained iteration: 202\n",
      "Trained iteration: 203\n",
      "Trained iteration: 204\n",
      "Trained iteration: 205\n",
      "Trained iteration: 206\n",
      "Trained iteration: 207\n",
      "Trained iteration: 208\n",
      "Trained iteration: 209\n",
      "Trained iteration: 210\n",
      "Trained iteration: 211\n",
      "Trained iteration: 212\n",
      "Trained iteration: 213\n",
      "Trained iteration: 214\n",
      "Trained iteration: 215\n",
      "Trained iteration: 216\n",
      "Trained iteration: 217\n",
      "Trained iteration: 218\n",
      "Trained iteration: 219\n",
      "Trained iteration: 220\n",
      "Trained iteration: 221\n",
      "Trained iteration: 222\n",
      "Trained iteration: 223\n",
      "Trained iteration: 224\n",
      "Trained iteration: 225\n",
      "Trained iteration: 226\n",
      "Trained iteration: 227\n",
      "Trained iteration: 228\n",
      "Trained iteration: 229\n",
      "Trained iteration: 230\n",
      "Trained iteration: 231\n",
      "Trained iteration: 232\n",
      "Trained iteration: 233\n",
      "Trained iteration: 234\n",
      "Trained iteration: 235\n",
      "Trained iteration: 236\n",
      "Trained iteration: 237\n",
      "Trained iteration: 238\n",
      "Trained iteration: 239\n",
      "Trained iteration: 240\n",
      "Trained iteration: 241\n",
      "Trained iteration: 242\n",
      "Trained iteration: 243\n",
      "Trained iteration: 244\n",
      "Trained iteration: 245\n",
      "Trained iteration: 246\n",
      "Trained iteration: 247\n",
      "Trained iteration: 248\n",
      "Trained iteration: 249\n",
      "Trained iteration: 250\n",
      "Trained iteration: 251\n",
      "Trained iteration: 252\n",
      "Trained iteration: 253\n",
      "Trained iteration: 254\n",
      "Trained iteration: 255\n",
      "Trained iteration: 256\n",
      "Trained iteration: 257\n",
      "Trained iteration: 258\n",
      "Trained iteration: 259\n",
      "Trained iteration: 260\n",
      "Trained iteration: 261\n",
      "Trained iteration: 262\n",
      "Trained iteration: 263\n",
      "Trained iteration: 264\n",
      "Trained iteration: 265\n",
      "Trained iteration: 266\n",
      "Trained iteration: 267\n",
      "Trained iteration: 268\n",
      "Trained iteration: 269\n",
      "Trained iteration: 270\n",
      "Trained iteration: 271\n",
      "Trained iteration: 272\n",
      "Trained iteration: 273\n",
      "Trained iteration: 274\n",
      "Trained iteration: 275\n",
      "Trained iteration: 276\n",
      "Trained iteration: 277\n",
      "Trained iteration: 278\n",
      "Trained iteration: 279\n",
      "Trained iteration: 280\n",
      "Trained iteration: 281\n",
      "Trained iteration: 282\n",
      "Trained iteration: 283\n",
      "Trained iteration: 284\n",
      "Trained iteration: 285\n",
      "Trained iteration: 286\n",
      "Trained iteration: 287\n",
      "Trained iteration: 288\n",
      "Trained iteration: 289\n",
      "Trained iteration: 290\n",
      "Trained iteration: 291\n",
      "Trained iteration: 292\n",
      "Trained iteration: 293\n",
      "Trained iteration: 294\n",
      "Trained iteration: 295\n",
      "Trained iteration: 296\n",
      "Trained iteration: 297\n",
      "Trained iteration: 298\n",
      "Trained iteration: 299\n",
      "Trained iteration: 300\n",
      "Trained iteration: 301\n",
      "Trained iteration: 302\n",
      "Trained iteration: 303\n",
      "Trained iteration: 304\n",
      "Trained iteration: 305\n",
      "Trained iteration: 306\n",
      "Trained iteration: 307\n",
      "Trained iteration: 308\n",
      "Trained iteration: 309\n",
      "Trained iteration: 310\n",
      "Trained iteration: 311\n",
      "Trained iteration: 312\n",
      "Trained iteration: 313\n",
      "Trained iteration: 314\n",
      "Trained iteration: 315\n",
      "Trained iteration: 316\n",
      "Trained iteration: 317\n",
      "Trained iteration: 318\n",
      "Trained iteration: 319\n",
      "Trained iteration: 320\n",
      "Trained iteration: 321\n",
      "Trained iteration: 322\n",
      "Trained iteration: 323\n",
      "Trained iteration: 324\n",
      "Trained iteration: 325\n",
      "Trained iteration: 326\n",
      "Trained iteration: 327\n",
      "Trained iteration: 328\n",
      "Trained iteration: 329\n",
      "Trained iteration: 330\n",
      "Trained iteration: 331\n",
      "Trained iteration: 332\n",
      "Trained iteration: 333\n",
      "Trained iteration: 334\n",
      "Trained iteration: 335\n",
      "Trained iteration: 336\n",
      "Trained iteration: 337\n",
      "Trained iteration: 338\n",
      "Trained iteration: 339\n",
      "Trained iteration: 340\n",
      "Trained iteration: 341\n",
      "Trained iteration: 342\n",
      "Trained iteration: 343\n",
      "Trained iteration: 344\n",
      "Trained iteration: 345\n",
      "Trained iteration: 346\n",
      "Trained iteration: 347\n",
      "Trained iteration: 348\n",
      "Trained iteration: 349\n",
      "Trained iteration: 350\n",
      "Trained iteration: 351\n",
      "Trained iteration: 352\n",
      "Trained iteration: 353\n",
      "Trained iteration: 354\n",
      "Trained iteration: 355\n",
      "Trained iteration: 356\n",
      "Trained iteration: 357\n",
      "Trained iteration: 358\n",
      "Trained iteration: 359\n",
      "Trained iteration: 360\n",
      "Trained iteration: 361\n",
      "Trained iteration: 362\n",
      "Trained iteration: 363\n",
      "Trained iteration: 364\n",
      "Trained iteration: 365\n",
      "Trained iteration: 366\n",
      "Trained iteration: 367\n",
      "Trained iteration: 368\n",
      "Trained iteration: 369\n",
      "Trained iteration: 370\n",
      "Trained iteration: 371\n",
      "Trained iteration: 372\n",
      "Trained iteration: 373\n",
      "Trained iteration: 374\n",
      "Trained iteration: 375\n",
      "Trained iteration: 376\n",
      "Trained iteration: 377\n",
      "Trained iteration: 378\n",
      "Trained iteration: 379\n",
      "Trained iteration: 380\n",
      "Trained iteration: 381\n",
      "Trained iteration: 382\n",
      "Trained iteration: 383\n",
      "Trained iteration: 384\n",
      "Trained iteration: 385\n",
      "Trained iteration: 386\n",
      "Trained iteration: 387\n",
      "Trained iteration: 388\n",
      "Trained iteration: 389\n",
      "Trained iteration: 390\n",
      "Trained iteration: 391\n",
      "Trained iteration: 392\n",
      "Trained iteration: 393\n",
      "Trained iteration: 394\n",
      "Trained iteration: 395\n",
      "Trained iteration: 396\n",
      "Trained iteration: 397\n",
      "Trained iteration: 398\n",
      "Trained iteration: 399\n",
      "Trained iteration: 400\n",
      "Trained iteration: 401\n",
      "Trained iteration: 402\n",
      "Trained iteration: 403\n",
      "Trained iteration: 404\n",
      "Trained iteration: 405\n",
      "Trained iteration: 406\n",
      "Trained iteration: 407\n",
      "Trained iteration: 408\n",
      "Trained iteration: 409\n",
      "Trained iteration: 410\n",
      "Trained iteration: 411\n",
      "Trained iteration: 412\n",
      "Trained iteration: 413\n",
      "Trained iteration: 414\n",
      "Trained iteration: 415\n",
      "Trained iteration: 416\n",
      "Trained iteration: 417\n",
      "Trained iteration: 418\n",
      "Trained iteration: 419\n",
      "Trained iteration: 420\n",
      "Trained iteration: 421\n",
      "Trained iteration: 422\n",
      "Trained iteration: 423\n",
      "Trained iteration: 424\n",
      "Trained iteration: 425\n",
      "Trained iteration: 426\n",
      "Trained iteration: 427\n",
      "Trained iteration: 428\n",
      "Trained iteration: 429\n",
      "Trained iteration: 430\n",
      "Trained iteration: 431\n",
      "Trained iteration: 432\n",
      "Trained iteration: 433\n",
      "Trained iteration: 434\n",
      "Trained iteration: 435\n",
      "Trained iteration: 436\n",
      "Trained iteration: 437\n",
      "Trained iteration: 438\n",
      "Trained iteration: 439\n",
      "Trained iteration: 440\n",
      "Trained iteration: 441\n",
      "Trained iteration: 442\n",
      "Trained iteration: 443\n",
      "Trained iteration: 444\n",
      "Trained iteration: 445\n",
      "Trained iteration: 446\n",
      "Trained iteration: 447\n",
      "Trained iteration: 448\n",
      "Trained iteration: 449\n",
      "Trained iteration: 450\n",
      "Trained iteration: 451\n",
      "Trained iteration: 452\n",
      "Trained iteration: 453\n",
      "Trained iteration: 454\n",
      "Trained iteration: 455\n",
      "Trained iteration: 456\n",
      "Trained iteration: 457\n",
      "Trained iteration: 458\n",
      "Trained iteration: 459\n",
      "Trained iteration: 460\n",
      "Trained iteration: 461\n",
      "Trained iteration: 462\n",
      "Trained iteration: 463\n",
      "Trained iteration: 464\n",
      "Trained iteration: 465\n",
      "Trained iteration: 466\n",
      "Trained iteration: 467\n",
      "Trained iteration: 468\n",
      "Trained iteration: 469\n",
      "Trained iteration: 470\n",
      "Trained iteration: 471\n",
      "Trained iteration: 472\n",
      "Trained iteration: 473\n",
      "Trained iteration: 474\n",
      "Trained iteration: 475\n",
      "Trained iteration: 476\n",
      "Trained iteration: 477\n",
      "Trained iteration: 478\n",
      "Trained iteration: 479\n",
      "Trained iteration: 480\n",
      "Trained iteration: 481\n",
      "Trained iteration: 482\n",
      "Trained iteration: 483\n",
      "Trained iteration: 484\n",
      "Trained iteration: 485\n",
      "Trained iteration: 486\n",
      "Trained iteration: 487\n",
      "Trained iteration: 488\n",
      "Trained iteration: 489\n",
      "Trained iteration: 490\n",
      "Trained iteration: 491\n",
      "Trained iteration: 492\n",
      "Trained iteration: 493\n",
      "Trained iteration: 494\n",
      "Trained iteration: 495\n",
      "Trained iteration: 496\n",
      "Trained iteration: 497\n",
      "Trained iteration: 498\n",
      "Trained iteration: 499\n",
      "Trained iteration: 500\n",
      "Trained iteration: 501\n",
      "Trained iteration: 502\n",
      "Trained iteration: 503\n",
      "Trained iteration: 504\n",
      "Trained iteration: 505\n",
      "Trained iteration: 506\n",
      "Trained iteration: 507\n",
      "Trained iteration: 508\n",
      "Trained iteration: 509\n",
      "Trained iteration: 510\n",
      "Trained iteration: 511\n",
      "Trained iteration: 512\n",
      "Trained iteration: 513\n",
      "Trained iteration: 514\n",
      "Trained iteration: 515\n",
      "Trained iteration: 516\n",
      "Trained iteration: 517\n",
      "Trained iteration: 518\n",
      "Trained iteration: 519\n",
      "Trained iteration: 520\n",
      "Trained iteration: 521\n",
      "Trained iteration: 522\n",
      "Trained iteration: 523\n",
      "Trained iteration: 524\n",
      "Trained iteration: 525\n",
      "Trained iteration: 526\n",
      "Trained iteration: 527\n",
      "Trained iteration: 528\n",
      "Trained iteration: 529\n",
      "Trained iteration: 530\n",
      "Trained iteration: 531\n",
      "Trained iteration: 532\n",
      "Trained iteration: 533\n",
      "Trained iteration: 534\n",
      "Trained iteration: 535\n",
      "Trained iteration: 536\n",
      "Trained iteration: 537\n",
      "Trained iteration: 538\n",
      "Trained iteration: 539\n",
      "Trained iteration: 540\n",
      "Trained iteration: 541\n",
      "Trained iteration: 542\n",
      "Trained iteration: 543\n",
      "Trained iteration: 544\n",
      "Trained iteration: 545\n",
      "Trained iteration: 546\n",
      "Trained iteration: 547\n",
      "Trained iteration: 548\n",
      "Trained iteration: 549\n",
      "Trained iteration: 550\n",
      "Trained iteration: 551\n",
      "Trained iteration: 552\n",
      "Trained iteration: 553\n",
      "Trained iteration: 554\n",
      "Trained iteration: 555\n",
      "Trained iteration: 556\n",
      "Trained iteration: 557\n",
      "Trained iteration: 558\n",
      "Trained iteration: 559\n",
      "Trained iteration: 560\n",
      "Trained iteration: 561\n",
      "Trained iteration: 562\n",
      "Trained iteration: 563\n",
      "Trained iteration: 564\n",
      "Trained iteration: 565\n",
      "Trained iteration: 566\n",
      "Trained iteration: 567\n",
      "Trained iteration: 568\n",
      "Trained iteration: 569\n",
      "Trained iteration: 570\n",
      "Trained iteration: 571\n",
      "Trained iteration: 572\n",
      "Trained iteration: 573\n",
      "Trained iteration: 574\n",
      "Trained iteration: 575\n",
      "Trained iteration: 576\n",
      "Trained iteration: 577\n",
      "Trained iteration: 578\n",
      "Trained iteration: 579\n",
      "Trained iteration: 580\n",
      "Trained iteration: 581\n",
      "Trained iteration: 582\n",
      "Trained iteration: 583\n",
      "Trained iteration: 584\n",
      "Trained iteration: 585\n",
      "Trained iteration: 586\n",
      "Trained iteration: 587\n",
      "Trained iteration: 588\n",
      "Trained iteration: 589\n",
      "Trained iteration: 590\n",
      "Trained iteration: 591\n",
      "Trained iteration: 592\n",
      "Trained iteration: 593\n",
      "Trained iteration: 594\n",
      "Trained iteration: 595\n",
      "Trained iteration: 596\n",
      "Trained iteration: 597\n",
      "Trained iteration: 598\n",
      "Trained iteration: 599\n",
      "Trained iteration: 600\n",
      "Trained iteration: 601\n",
      "Trained iteration: 602\n",
      "Trained iteration: 603\n",
      "Trained iteration: 604\n",
      "Trained iteration: 605\n",
      "Trained iteration: 606\n",
      "Trained iteration: 607\n",
      "Trained iteration: 608\n",
      "Trained iteration: 609\n",
      "Trained iteration: 610\n",
      "Trained iteration: 611\n",
      "Trained iteration: 612\n",
      "Trained iteration: 613\n",
      "Trained iteration: 614\n",
      "Trained iteration: 615\n",
      "Trained iteration: 616\n",
      "Trained iteration: 617\n",
      "Trained iteration: 618\n",
      "Trained iteration: 619\n",
      "Trained iteration: 620\n",
      "Trained iteration: 621\n",
      "Trained iteration: 622\n",
      "Trained iteration: 623\n",
      "Trained iteration: 624\n",
      "Trained iteration: 625\n",
      "Trained iteration: 626\n",
      "Trained iteration: 627\n",
      "Trained iteration: 628\n",
      "Trained iteration: 629\n",
      "Trained iteration: 630\n",
      "Trained iteration: 631\n",
      "Trained iteration: 632\n",
      "Trained iteration: 633\n",
      "Trained iteration: 634\n",
      "Trained iteration: 635\n",
      "Trained iteration: 636\n",
      "Trained iteration: 637\n",
      "Trained iteration: 638\n",
      "Trained iteration: 639\n",
      "Trained iteration: 640\n",
      "Trained iteration: 641\n",
      "Trained iteration: 642\n",
      "Trained iteration: 643\n",
      "Trained iteration: 644\n",
      "Trained iteration: 645\n",
      "Trained iteration: 646\n",
      "Trained iteration: 647\n",
      "Trained iteration: 648\n",
      "Trained iteration: 649\n",
      "Trained iteration: 650\n",
      "Trained iteration: 651\n",
      "Trained iteration: 652\n",
      "Trained iteration: 653\n",
      "Trained iteration: 654\n",
      "Trained iteration: 655\n",
      "Trained iteration: 656\n",
      "Trained iteration: 657\n",
      "Trained iteration: 658\n",
      "Trained iteration: 659\n",
      "Trained iteration: 660\n",
      "Trained iteration: 661\n",
      "Trained iteration: 662\n",
      "Trained iteration: 663\n",
      "Trained iteration: 664\n",
      "Trained iteration: 665\n",
      "Trained iteration: 666\n",
      "Trained iteration: 667\n",
      "Trained iteration: 668\n",
      "Trained iteration: 669\n",
      "Trained iteration: 670\n",
      "Trained iteration: 671\n",
      "Trained iteration: 672\n",
      "Trained iteration: 673\n",
      "Trained iteration: 674\n",
      "Trained iteration: 675\n",
      "Trained iteration: 676\n",
      "Trained iteration: 677\n",
      "Trained iteration: 678\n",
      "Trained iteration: 679\n",
      "Trained iteration: 680\n",
      "Trained iteration: 681\n",
      "Trained iteration: 682\n",
      "Trained iteration: 683\n",
      "Trained iteration: 684\n",
      "Trained iteration: 685\n",
      "Trained iteration: 686\n",
      "Trained iteration: 687\n",
      "Trained iteration: 688\n",
      "Trained iteration: 689\n",
      "Trained iteration: 690\n",
      "Trained iteration: 691\n",
      "Trained iteration: 692\n",
      "Trained iteration: 693\n",
      "Trained iteration: 694\n",
      "Trained iteration: 695\n",
      "Trained iteration: 696\n",
      "Trained iteration: 697\n",
      "Trained iteration: 698\n",
      "Trained iteration: 699\n",
      "Trained iteration: 700\n",
      "Trained iteration: 701\n",
      "Trained iteration: 702\n",
      "Trained iteration: 703\n",
      "Trained iteration: 704\n",
      "Trained iteration: 705\n",
      "Trained iteration: 706\n",
      "Trained iteration: 707\n",
      "Trained iteration: 708\n",
      "Trained iteration: 709\n",
      "Trained iteration: 710\n",
      "Trained iteration: 711\n",
      "Trained iteration: 712\n",
      "Trained iteration: 713\n",
      "Trained iteration: 714\n",
      "Trained iteration: 715\n",
      "Trained iteration: 716\n",
      "Trained iteration: 717\n",
      "Trained iteration: 718\n",
      "Trained iteration: 719\n",
      "Trained iteration: 720\n",
      "Trained iteration: 721\n",
      "Trained iteration: 722\n",
      "Trained iteration: 723\n",
      "Trained iteration: 724\n",
      "Trained iteration: 725\n",
      "Trained iteration: 726\n",
      "Trained iteration: 727\n",
      "Trained iteration: 728\n",
      "Trained iteration: 729\n",
      "Trained iteration: 730\n",
      "Trained iteration: 731\n",
      "Trained iteration: 732\n",
      "Trained iteration: 733\n",
      "Trained iteration: 734\n",
      "Trained iteration: 735\n",
      "Trained iteration: 736\n",
      "Trained iteration: 737\n",
      "Trained iteration: 738\n",
      "Trained iteration: 739\n",
      "Trained iteration: 740\n",
      "Trained iteration: 741\n",
      "Trained iteration: 742\n",
      "Trained iteration: 743\n",
      "Trained iteration: 744\n",
      "Trained iteration: 745\n",
      "Trained iteration: 746\n",
      "Trained iteration: 747\n",
      "Trained iteration: 748\n",
      "Trained iteration: 749\n",
      "Trained iteration: 750\n",
      "Trained iteration: 751\n",
      "Trained iteration: 752\n",
      "Trained iteration: 753\n",
      "Trained iteration: 754\n",
      "Trained iteration: 755\n",
      "Trained iteration: 756\n",
      "Trained iteration: 757\n",
      "Trained iteration: 758\n",
      "Trained iteration: 759\n",
      "Trained iteration: 760\n",
      "Trained iteration: 761\n",
      "Trained iteration: 762\n",
      "Trained iteration: 763\n",
      "Trained iteration: 764\n",
      "Trained iteration: 765\n",
      "Trained iteration: 766\n",
      "Trained iteration: 767\n",
      "Trained iteration: 768\n",
      "Trained iteration: 769\n",
      "Trained iteration: 770\n",
      "Trained iteration: 771\n",
      "Trained iteration: 772\n",
      "Trained iteration: 773\n",
      "Trained iteration: 774\n",
      "Trained iteration: 775\n",
      "Trained iteration: 776\n",
      "Trained iteration: 777\n",
      "Trained iteration: 778\n",
      "Trained iteration: 779\n",
      "Trained iteration: 780\n",
      "Trained iteration: 781\n",
      "Trained iteration: 782\n",
      "Trained iteration: 783\n",
      "Trained iteration: 784\n",
      "Trained iteration: 785\n",
      "Trained iteration: 786\n",
      "Trained iteration: 787\n",
      "Trained iteration: 788\n",
      "Trained iteration: 789\n",
      "Trained iteration: 790\n",
      "Trained iteration: 791\n",
      "Trained iteration: 792\n",
      "Trained iteration: 793\n",
      "Trained iteration: 794\n",
      "Trained iteration: 795\n",
      "Trained iteration: 796\n",
      "Trained iteration: 797\n",
      "Trained iteration: 798\n",
      "Trained iteration: 799\n",
      "Trained iteration: 800\n",
      "Trained iteration: 801\n",
      "Trained iteration: 802\n",
      "Trained iteration: 803\n",
      "Trained iteration: 804\n",
      "Trained iteration: 805\n",
      "Trained iteration: 806\n",
      "Trained iteration: 807\n",
      "Trained iteration: 808\n",
      "Trained iteration: 809\n",
      "Trained iteration: 810\n",
      "Trained iteration: 811\n",
      "Trained iteration: 812\n",
      "Trained iteration: 813\n",
      "Trained iteration: 814\n",
      "Trained iteration: 815\n",
      "Trained iteration: 816\n",
      "Trained iteration: 817\n",
      "Trained iteration: 818\n",
      "Trained iteration: 819\n",
      "Trained iteration: 820\n",
      "Trained iteration: 821\n",
      "Trained iteration: 822\n",
      "Trained iteration: 823\n",
      "Trained iteration: 824\n",
      "Trained iteration: 825\n",
      "Trained iteration: 826\n",
      "Trained iteration: 827\n",
      "Trained iteration: 828\n",
      "Trained iteration: 829\n",
      "Trained iteration: 830\n",
      "Trained iteration: 831\n",
      "Trained iteration: 832\n",
      "Trained iteration: 833\n",
      "Trained iteration: 834\n",
      "Trained iteration: 835\n",
      "Trained iteration: 836\n",
      "Trained iteration: 837\n",
      "Trained iteration: 838\n",
      "Trained iteration: 839\n",
      "Trained iteration: 840\n",
      "Trained iteration: 841\n",
      "Trained iteration: 842\n",
      "Trained iteration: 843\n",
      "Trained iteration: 844\n",
      "Trained iteration: 845\n",
      "Trained iteration: 846\n",
      "Trained iteration: 847\n",
      "Trained iteration: 848\n",
      "Trained iteration: 849\n",
      "Trained iteration: 850\n",
      "Trained iteration: 851\n",
      "Trained iteration: 852\n",
      "Trained iteration: 853\n",
      "Trained iteration: 854\n",
      "Trained iteration: 855\n",
      "Trained iteration: 856\n",
      "Trained iteration: 857\n",
      "Trained iteration: 858\n",
      "Trained iteration: 859\n",
      "Trained iteration: 860\n",
      "Trained iteration: 861\n",
      "Trained iteration: 862\n",
      "Trained iteration: 863\n",
      "Trained iteration: 864\n",
      "Trained iteration: 865\n",
      "Trained iteration: 866\n",
      "Trained iteration: 867\n",
      "Trained iteration: 868\n",
      "Trained iteration: 869\n",
      "Trained iteration: 870\n",
      "Trained iteration: 871\n",
      "Trained iteration: 872\n",
      "Trained iteration: 873\n",
      "Trained iteration: 874\n",
      "Trained iteration: 875\n",
      "Trained iteration: 876\n",
      "Trained iteration: 877\n",
      "Trained iteration: 878\n",
      "Trained iteration: 879\n",
      "Trained iteration: 880\n",
      "Trained iteration: 881\n",
      "Trained iteration: 882\n",
      "Trained iteration: 883\n",
      "Trained iteration: 884\n",
      "Trained iteration: 885\n",
      "Trained iteration: 886\n",
      "Trained iteration: 887\n",
      "Trained iteration: 888\n",
      "Trained iteration: 889\n",
      "Trained iteration: 890\n",
      "Trained iteration: 891\n",
      "Trained iteration: 892\n",
      "Trained iteration: 893\n",
      "Trained iteration: 894\n",
      "Trained iteration: 895\n",
      "Trained iteration: 896\n",
      "Trained iteration: 897\n",
      "Trained iteration: 898\n",
      "Trained iteration: 899\n",
      "Trained iteration: 900\n",
      "Trained iteration: 901\n",
      "Trained iteration: 902\n",
      "Trained iteration: 903\n",
      "Trained iteration: 904\n",
      "Trained iteration: 905\n",
      "Trained iteration: 906\n",
      "Trained iteration: 907\n",
      "Trained iteration: 908\n",
      "Trained iteration: 909\n",
      "Trained iteration: 910\n",
      "Trained iteration: 911\n",
      "Trained iteration: 912\n",
      "Trained iteration: 913\n",
      "Trained iteration: 914\n",
      "Trained iteration: 915\n",
      "Trained iteration: 916\n",
      "Trained iteration: 917\n",
      "Trained iteration: 918\n",
      "Trained iteration: 919\n",
      "Trained iteration: 920\n",
      "Trained iteration: 921\n",
      "Trained iteration: 922\n",
      "Trained iteration: 923\n",
      "Trained iteration: 924\n",
      "Trained iteration: 925\n",
      "Trained iteration: 926\n",
      "Trained iteration: 927\n",
      "Trained iteration: 928\n",
      "Trained iteration: 929\n",
      "Trained iteration: 930\n",
      "Trained iteration: 931\n",
      "Trained iteration: 932\n",
      "Trained iteration: 933\n",
      "Trained iteration: 934\n",
      "Trained iteration: 935\n",
      "Trained iteration: 936\n",
      "Trained iteration: 937\n",
      "Trained iteration: 0\n",
      "Trained iteration: 1\n",
      "Trained iteration: 2\n",
      "Trained iteration: 3\n",
      "Trained iteration: 4\n",
      "Trained iteration: 5\n",
      "Trained iteration: 6\n",
      "Trained iteration: 7\n",
      "Trained iteration: 8\n",
      "Trained iteration: 9\n",
      "Trained iteration: 10\n",
      "Trained iteration: 11\n",
      "Trained iteration: 12\n",
      "Trained iteration: 13\n",
      "Trained iteration: 14\n",
      "Trained iteration: 15\n",
      "Trained iteration: 16\n",
      "Trained iteration: 17\n",
      "Trained iteration: 18\n",
      "Trained iteration: 19\n",
      "Trained iteration: 20\n",
      "Trained iteration: 21\n",
      "Trained iteration: 22\n",
      "Trained iteration: 23\n",
      "Trained iteration: 24\n",
      "Trained iteration: 25\n",
      "Trained iteration: 26\n",
      "Trained iteration: 27\n",
      "Trained iteration: 28\n",
      "Trained iteration: 29\n",
      "Trained iteration: 30\n",
      "Trained iteration: 31\n",
      "Trained iteration: 32\n",
      "Trained iteration: 33\n",
      "Trained iteration: 34\n",
      "Trained iteration: 35\n",
      "Trained iteration: 36\n",
      "Trained iteration: 37\n",
      "Trained iteration: 38\n",
      "Trained iteration: 39\n",
      "Trained iteration: 40\n",
      "Trained iteration: 41\n",
      "Trained iteration: 42\n",
      "Trained iteration: 43\n",
      "Trained iteration: 44\n",
      "Trained iteration: 45\n",
      "Trained iteration: 46\n",
      "Trained iteration: 47\n",
      "Trained iteration: 48\n",
      "Trained iteration: 49\n",
      "Trained iteration: 50\n",
      "Trained iteration: 51\n",
      "Trained iteration: 52\n",
      "Trained iteration: 53\n",
      "Trained iteration: 54\n",
      "Trained iteration: 55\n",
      "Trained iteration: 56\n",
      "Trained iteration: 57\n",
      "Trained iteration: 58\n",
      "Trained iteration: 59\n",
      "Trained iteration: 60\n",
      "Trained iteration: 61\n",
      "Trained iteration: 62\n",
      "Trained iteration: 63\n",
      "Trained iteration: 64\n",
      "Trained iteration: 65\n",
      "Trained iteration: 66\n",
      "Trained iteration: 67\n",
      "Trained iteration: 68\n",
      "Trained iteration: 69\n",
      "Trained iteration: 70\n",
      "Trained iteration: 71\n",
      "Trained iteration: 72\n",
      "Trained iteration: 73\n",
      "Trained iteration: 74\n",
      "Trained iteration: 75\n",
      "Trained iteration: 76\n",
      "Trained iteration: 77\n",
      "Trained iteration: 78\n",
      "Trained iteration: 79\n",
      "Trained iteration: 80\n",
      "Trained iteration: 81\n",
      "Trained iteration: 82\n",
      "Trained iteration: 83\n",
      "Trained iteration: 84\n",
      "Trained iteration: 85\n",
      "Trained iteration: 86\n",
      "Trained iteration: 87\n",
      "Trained iteration: 88\n",
      "Trained iteration: 89\n",
      "Trained iteration: 90\n",
      "Trained iteration: 91\n",
      "Trained iteration: 92\n",
      "Trained iteration: 93\n",
      "Trained iteration: 94\n",
      "Trained iteration: 95\n",
      "Trained iteration: 96\n",
      "Trained iteration: 97\n",
      "Trained iteration: 98\n",
      "Trained iteration: 99\n",
      "Trained iteration: 100\n",
      "Trained iteration: 101\n",
      "Trained iteration: 102\n",
      "Trained iteration: 103\n",
      "Trained iteration: 104\n",
      "Trained iteration: 105\n",
      "Trained iteration: 106\n",
      "Trained iteration: 107\n",
      "Trained iteration: 108\n",
      "Trained iteration: 109\n",
      "Trained iteration: 110\n",
      "Trained iteration: 111\n",
      "Trained iteration: 112\n",
      "Trained iteration: 113\n",
      "Trained iteration: 114\n",
      "Trained iteration: 115\n",
      "Trained iteration: 116\n",
      "Trained iteration: 117\n",
      "Trained iteration: 118\n",
      "Trained iteration: 119\n",
      "Trained iteration: 120\n",
      "Trained iteration: 121\n",
      "Trained iteration: 122\n",
      "Trained iteration: 123\n",
      "Trained iteration: 124\n",
      "Trained iteration: 125\n",
      "Trained iteration: 126\n",
      "Trained iteration: 127\n",
      "Trained iteration: 128\n",
      "Trained iteration: 129\n",
      "Trained iteration: 130\n",
      "Trained iteration: 131\n",
      "Trained iteration: 132\n",
      "Trained iteration: 133\n",
      "Trained iteration: 134\n",
      "Trained iteration: 135\n",
      "Trained iteration: 136\n",
      "Trained iteration: 137\n",
      "Trained iteration: 138\n",
      "Trained iteration: 139\n",
      "Trained iteration: 140\n",
      "Trained iteration: 141\n",
      "Trained iteration: 142\n",
      "Trained iteration: 143\n",
      "Trained iteration: 144\n",
      "Trained iteration: 145\n",
      "Trained iteration: 146\n",
      "Trained iteration: 147\n",
      "Trained iteration: 148\n",
      "Trained iteration: 149\n",
      "Trained iteration: 150\n",
      "Trained iteration: 151\n",
      "Trained iteration: 152\n",
      "Trained iteration: 153\n",
      "Trained iteration: 154\n",
      "Trained iteration: 155\n",
      "Trained iteration: 156\n",
      "Trained iteration: 157\n",
      "Trained iteration: 158\n",
      "Trained iteration: 159\n",
      "Trained iteration: 160\n",
      "Trained iteration: 161\n",
      "Trained iteration: 162\n",
      "Trained iteration: 163\n",
      "Trained iteration: 164\n",
      "Trained iteration: 165\n",
      "Trained iteration: 166\n",
      "Trained iteration: 167\n",
      "Trained iteration: 168\n",
      "Trained iteration: 169\n",
      "Trained iteration: 170\n",
      "Trained iteration: 171\n",
      "Trained iteration: 172\n",
      "Trained iteration: 173\n",
      "Trained iteration: 174\n",
      "Trained iteration: 175\n",
      "Trained iteration: 176\n",
      "Trained iteration: 177\n",
      "Trained iteration: 178\n",
      "Trained iteration: 179\n",
      "Trained iteration: 180\n",
      "Trained iteration: 181\n",
      "Trained iteration: 182\n",
      "Trained iteration: 183\n",
      "Trained iteration: 184\n",
      "Trained iteration: 185\n",
      "Trained iteration: 186\n",
      "Trained iteration: 187\n",
      "Trained iteration: 188\n",
      "Trained iteration: 189\n",
      "Trained iteration: 190\n",
      "Trained iteration: 191\n",
      "Trained iteration: 192\n",
      "Trained iteration: 193\n",
      "Trained iteration: 194\n",
      "Trained iteration: 195\n",
      "Trained iteration: 196\n",
      "Trained iteration: 197\n",
      "Trained iteration: 198\n",
      "Trained iteration: 199\n",
      "Trained iteration: 200\n",
      "Trained iteration: 201\n",
      "Trained iteration: 202\n",
      "Trained iteration: 203\n",
      "Trained iteration: 204\n",
      "Trained iteration: 205\n",
      "Trained iteration: 206\n",
      "Trained iteration: 207\n",
      "Trained iteration: 208\n",
      "Trained iteration: 209\n",
      "Trained iteration: 210\n",
      "Trained iteration: 211\n",
      "Trained iteration: 212\n",
      "Trained iteration: 213\n",
      "Trained iteration: 214\n",
      "Trained iteration: 215\n",
      "Trained iteration: 216\n",
      "Trained iteration: 217\n",
      "Trained iteration: 218\n",
      "Trained iteration: 219\n",
      "Trained iteration: 220\n",
      "Trained iteration: 221\n",
      "Trained iteration: 222\n",
      "Trained iteration: 223\n",
      "Trained iteration: 224\n",
      "Trained iteration: 225\n",
      "Trained iteration: 226\n",
      "Trained iteration: 227\n",
      "Trained iteration: 228\n",
      "Trained iteration: 229\n",
      "Trained iteration: 230\n",
      "Trained iteration: 231\n",
      "Trained iteration: 232\n",
      "Trained iteration: 233\n",
      "Trained iteration: 234\n",
      "Trained iteration: 235\n",
      "Trained iteration: 236\n",
      "Trained iteration: 237\n",
      "Trained iteration: 238\n",
      "Trained iteration: 239\n",
      "Trained iteration: 240\n",
      "Trained iteration: 241\n",
      "Trained iteration: 242\n",
      "Trained iteration: 243\n",
      "Trained iteration: 244\n",
      "Trained iteration: 245\n",
      "Trained iteration: 246\n",
      "Trained iteration: 247\n",
      "Trained iteration: 248\n",
      "Trained iteration: 249\n",
      "Trained iteration: 250\n",
      "Trained iteration: 251\n",
      "Trained iteration: 252\n",
      "Trained iteration: 253\n",
      "Trained iteration: 254\n",
      "Trained iteration: 255\n",
      "Trained iteration: 256\n",
      "Trained iteration: 257\n",
      "Trained iteration: 258\n",
      "Trained iteration: 259\n",
      "Trained iteration: 260\n",
      "Trained iteration: 261\n",
      "Trained iteration: 262\n",
      "Trained iteration: 263\n",
      "Trained iteration: 264\n",
      "Trained iteration: 265\n",
      "Trained iteration: 266\n",
      "Trained iteration: 267\n",
      "Trained iteration: 268\n",
      "Trained iteration: 269\n",
      "Trained iteration: 270\n",
      "Trained iteration: 271\n",
      "Trained iteration: 272\n",
      "Trained iteration: 273\n",
      "Trained iteration: 274\n",
      "Trained iteration: 275\n",
      "Trained iteration: 276\n",
      "Trained iteration: 277\n",
      "Trained iteration: 278\n",
      "Trained iteration: 279\n",
      "Trained iteration: 280\n",
      "Trained iteration: 281\n",
      "Trained iteration: 282\n",
      "Trained iteration: 283\n",
      "Trained iteration: 284\n",
      "Trained iteration: 285\n",
      "Trained iteration: 286\n",
      "Trained iteration: 287\n",
      "Trained iteration: 288\n",
      "Trained iteration: 289\n",
      "Trained iteration: 290\n",
      "Trained iteration: 291\n",
      "Trained iteration: 292\n",
      "Trained iteration: 293\n",
      "Trained iteration: 294\n",
      "Trained iteration: 295\n",
      "Trained iteration: 296\n",
      "Trained iteration: 297\n",
      "Trained iteration: 298\n",
      "Trained iteration: 299\n",
      "Trained iteration: 300\n",
      "Trained iteration: 301\n",
      "Trained iteration: 302\n",
      "Trained iteration: 303\n",
      "Trained iteration: 304\n",
      "Trained iteration: 305\n",
      "Trained iteration: 306\n",
      "Trained iteration: 307\n",
      "Trained iteration: 308\n",
      "Trained iteration: 309\n",
      "Trained iteration: 310\n",
      "Trained iteration: 311\n",
      "Trained iteration: 312\n",
      "Trained iteration: 313\n",
      "Trained iteration: 314\n",
      "Trained iteration: 315\n",
      "Trained iteration: 316\n",
      "Trained iteration: 317\n",
      "Trained iteration: 318\n",
      "Trained iteration: 319\n",
      "Trained iteration: 320\n",
      "Trained iteration: 321\n",
      "Trained iteration: 322\n",
      "Trained iteration: 323\n",
      "Trained iteration: 324\n",
      "Trained iteration: 325\n",
      "Trained iteration: 326\n",
      "Trained iteration: 327\n",
      "Trained iteration: 328\n",
      "Trained iteration: 329\n",
      "Trained iteration: 330\n",
      "Trained iteration: 331\n",
      "Trained iteration: 332\n",
      "Trained iteration: 333\n",
      "Trained iteration: 334\n",
      "Trained iteration: 335\n",
      "Trained iteration: 336\n",
      "Trained iteration: 337\n",
      "Trained iteration: 338\n",
      "Trained iteration: 339\n",
      "Trained iteration: 340\n",
      "Trained iteration: 341\n",
      "Trained iteration: 342\n",
      "Trained iteration: 343\n",
      "Trained iteration: 344\n",
      "Trained iteration: 345\n",
      "Trained iteration: 346\n",
      "Trained iteration: 347\n",
      "Trained iteration: 348\n",
      "Trained iteration: 349\n",
      "Trained iteration: 350\n",
      "Trained iteration: 351\n",
      "Trained iteration: 352\n",
      "Trained iteration: 353\n",
      "Trained iteration: 354\n",
      "Trained iteration: 355\n",
      "Trained iteration: 356\n",
      "Trained iteration: 357\n",
      "Trained iteration: 358\n",
      "Trained iteration: 359\n",
      "Trained iteration: 360\n",
      "Trained iteration: 361\n",
      "Trained iteration: 362\n",
      "Trained iteration: 363\n",
      "Trained iteration: 364\n",
      "Trained iteration: 365\n",
      "Trained iteration: 366\n",
      "Trained iteration: 367\n",
      "Trained iteration: 368\n",
      "Trained iteration: 369\n",
      "Trained iteration: 370\n",
      "Trained iteration: 371\n",
      "Trained iteration: 372\n",
      "Trained iteration: 373\n",
      "Trained iteration: 374\n",
      "Trained iteration: 375\n",
      "Trained iteration: 376\n",
      "Trained iteration: 377\n",
      "Trained iteration: 378\n",
      "Trained iteration: 379\n",
      "Trained iteration: 380\n",
      "Trained iteration: 381\n",
      "Trained iteration: 382\n",
      "Trained iteration: 383\n",
      "Trained iteration: 384\n",
      "Trained iteration: 385\n",
      "Trained iteration: 386\n",
      "Trained iteration: 387\n",
      "Trained iteration: 388\n",
      "Trained iteration: 389\n",
      "Trained iteration: 390\n",
      "Trained iteration: 391\n",
      "Trained iteration: 392\n",
      "Trained iteration: 393\n",
      "Trained iteration: 394\n",
      "Trained iteration: 395\n",
      "Trained iteration: 396\n",
      "Trained iteration: 397\n",
      "Trained iteration: 398\n",
      "Trained iteration: 399\n",
      "Trained iteration: 400\n",
      "Trained iteration: 401\n",
      "Trained iteration: 402\n",
      "Trained iteration: 403\n",
      "Trained iteration: 404\n",
      "Trained iteration: 405\n",
      "Trained iteration: 406\n",
      "Trained iteration: 407\n",
      "Trained iteration: 408\n",
      "Trained iteration: 409\n",
      "Trained iteration: 410\n",
      "Trained iteration: 411\n",
      "Trained iteration: 412\n",
      "Trained iteration: 413\n",
      "Trained iteration: 414\n",
      "Trained iteration: 415\n",
      "Trained iteration: 416\n",
      "Trained iteration: 417\n",
      "Trained iteration: 418\n",
      "Trained iteration: 419\n",
      "Trained iteration: 420\n",
      "Trained iteration: 421\n",
      "Trained iteration: 422\n",
      "Trained iteration: 423\n",
      "Trained iteration: 424\n",
      "Trained iteration: 425\n",
      "Trained iteration: 426\n",
      "Trained iteration: 427\n",
      "Trained iteration: 428\n",
      "Trained iteration: 429\n",
      "Trained iteration: 430\n",
      "Trained iteration: 431\n",
      "Trained iteration: 432\n",
      "Trained iteration: 433\n",
      "Trained iteration: 434\n",
      "Trained iteration: 435\n",
      "Trained iteration: 436\n",
      "Trained iteration: 437\n",
      "Trained iteration: 438\n",
      "Trained iteration: 439\n",
      "Trained iteration: 440\n",
      "Trained iteration: 441\n",
      "Trained iteration: 442\n",
      "Trained iteration: 443\n",
      "Trained iteration: 444\n",
      "Trained iteration: 445\n",
      "Trained iteration: 446\n",
      "Trained iteration: 447\n",
      "Trained iteration: 448\n",
      "Trained iteration: 449\n",
      "Trained iteration: 450\n",
      "Trained iteration: 451\n",
      "Trained iteration: 452\n",
      "Trained iteration: 453\n",
      "Trained iteration: 454\n",
      "Trained iteration: 455\n",
      "Trained iteration: 456\n",
      "Trained iteration: 457\n",
      "Trained iteration: 458\n",
      "Trained iteration: 459\n",
      "Trained iteration: 460\n",
      "Trained iteration: 461\n",
      "Trained iteration: 462\n",
      "Trained iteration: 463\n",
      "Trained iteration: 464\n",
      "Trained iteration: 465\n",
      "Trained iteration: 466\n",
      "Trained iteration: 467\n",
      "Trained iteration: 468\n",
      "Trained iteration: 469\n",
      "Trained iteration: 470\n",
      "Trained iteration: 471\n",
      "Trained iteration: 472\n",
      "Trained iteration: 473\n",
      "Trained iteration: 474\n",
      "Trained iteration: 475\n",
      "Trained iteration: 476\n",
      "Trained iteration: 477\n",
      "Trained iteration: 478\n",
      "Trained iteration: 479\n",
      "Trained iteration: 480\n",
      "Trained iteration: 481\n",
      "Trained iteration: 482\n",
      "Trained iteration: 483\n",
      "Trained iteration: 484\n",
      "Trained iteration: 485\n",
      "Trained iteration: 486\n",
      "Trained iteration: 487\n",
      "Trained iteration: 488\n",
      "Trained iteration: 489\n",
      "Trained iteration: 490\n",
      "Trained iteration: 491\n",
      "Trained iteration: 492\n",
      "Trained iteration: 493\n",
      "Trained iteration: 494\n",
      "Trained iteration: 495\n",
      "Trained iteration: 496\n",
      "Trained iteration: 497\n",
      "Trained iteration: 498\n",
      "Trained iteration: 499\n",
      "Trained iteration: 500\n",
      "Trained iteration: 501\n",
      "Trained iteration: 502\n",
      "Trained iteration: 503\n",
      "Trained iteration: 504\n",
      "Trained iteration: 505\n",
      "Trained iteration: 506\n",
      "Trained iteration: 507\n",
      "Trained iteration: 508\n",
      "Trained iteration: 509\n",
      "Trained iteration: 510\n",
      "Trained iteration: 511\n",
      "Trained iteration: 512\n",
      "Trained iteration: 513\n",
      "Trained iteration: 514\n",
      "Trained iteration: 515\n",
      "Trained iteration: 516\n",
      "Trained iteration: 517\n",
      "Trained iteration: 518\n",
      "Trained iteration: 519\n",
      "Trained iteration: 520\n",
      "Trained iteration: 521\n",
      "Trained iteration: 522\n",
      "Trained iteration: 523\n",
      "Trained iteration: 524\n",
      "Trained iteration: 525\n",
      "Trained iteration: 526\n",
      "Trained iteration: 527\n",
      "Trained iteration: 528\n",
      "Trained iteration: 529\n",
      "Trained iteration: 530\n",
      "Trained iteration: 531\n",
      "Trained iteration: 532\n",
      "Trained iteration: 533\n",
      "Trained iteration: 534\n",
      "Trained iteration: 535\n",
      "Trained iteration: 536\n",
      "Trained iteration: 537\n",
      "Trained iteration: 538\n",
      "Trained iteration: 539\n",
      "Trained iteration: 540\n",
      "Trained iteration: 541\n",
      "Trained iteration: 542\n",
      "Trained iteration: 543\n",
      "Trained iteration: 544\n",
      "Trained iteration: 545\n",
      "Trained iteration: 546\n",
      "Trained iteration: 547\n",
      "Trained iteration: 548\n",
      "Trained iteration: 549\n",
      "Trained iteration: 550\n",
      "Trained iteration: 551\n",
      "Trained iteration: 552\n",
      "Trained iteration: 553\n",
      "Trained iteration: 554\n",
      "Trained iteration: 555\n",
      "Trained iteration: 556\n",
      "Trained iteration: 557\n",
      "Trained iteration: 558\n",
      "Trained iteration: 559\n",
      "Trained iteration: 560\n",
      "Trained iteration: 561\n",
      "Trained iteration: 562\n",
      "Trained iteration: 563\n",
      "Trained iteration: 564\n",
      "Trained iteration: 565\n",
      "Trained iteration: 566\n",
      "Trained iteration: 567\n",
      "Trained iteration: 568\n",
      "Trained iteration: 569\n",
      "Trained iteration: 570\n",
      "Trained iteration: 571\n",
      "Trained iteration: 572\n",
      "Trained iteration: 573\n",
      "Trained iteration: 574\n",
      "Trained iteration: 575\n",
      "Trained iteration: 576\n",
      "Trained iteration: 577\n",
      "Trained iteration: 578\n",
      "Trained iteration: 579\n",
      "Trained iteration: 580\n",
      "Trained iteration: 581\n",
      "Trained iteration: 582\n",
      "Trained iteration: 583\n",
      "Trained iteration: 584\n",
      "Trained iteration: 585\n",
      "Trained iteration: 586\n",
      "Trained iteration: 587\n",
      "Trained iteration: 588\n",
      "Trained iteration: 589\n",
      "Trained iteration: 590\n",
      "Trained iteration: 591\n",
      "Trained iteration: 592\n",
      "Trained iteration: 593\n",
      "Trained iteration: 594\n",
      "Trained iteration: 595\n",
      "Trained iteration: 596\n",
      "Trained iteration: 597\n",
      "Trained iteration: 598\n",
      "Trained iteration: 599\n",
      "Trained iteration: 600\n",
      "Trained iteration: 601\n",
      "Trained iteration: 602\n",
      "Trained iteration: 603\n",
      "Trained iteration: 604\n",
      "Trained iteration: 605\n",
      "Trained iteration: 606\n",
      "Trained iteration: 607\n",
      "Trained iteration: 608\n",
      "Trained iteration: 609\n",
      "Trained iteration: 610\n",
      "Trained iteration: 611\n",
      "Trained iteration: 612\n",
      "Trained iteration: 613\n",
      "Trained iteration: 614\n",
      "Trained iteration: 615\n",
      "Trained iteration: 616\n",
      "Trained iteration: 617\n",
      "Trained iteration: 618\n",
      "Trained iteration: 619\n",
      "Trained iteration: 620\n",
      "Trained iteration: 621\n",
      "Trained iteration: 622\n",
      "Trained iteration: 623\n",
      "Trained iteration: 624\n",
      "Trained iteration: 625\n",
      "Trained iteration: 626\n",
      "Trained iteration: 627\n",
      "Trained iteration: 628\n",
      "Trained iteration: 629\n",
      "Trained iteration: 630\n",
      "Trained iteration: 631\n",
      "Trained iteration: 632\n",
      "Trained iteration: 633\n",
      "Trained iteration: 634\n",
      "Trained iteration: 635\n",
      "Trained iteration: 636\n",
      "Trained iteration: 637\n",
      "Trained iteration: 638\n",
      "Trained iteration: 639\n",
      "Trained iteration: 640\n",
      "Trained iteration: 641\n",
      "Trained iteration: 642\n",
      "Trained iteration: 643\n",
      "Trained iteration: 644\n",
      "Trained iteration: 645\n",
      "Trained iteration: 646\n",
      "Trained iteration: 647\n",
      "Trained iteration: 648\n",
      "Trained iteration: 649\n",
      "Trained iteration: 650\n",
      "Trained iteration: 651\n",
      "Trained iteration: 652\n",
      "Trained iteration: 653\n",
      "Trained iteration: 654\n",
      "Trained iteration: 655\n",
      "Trained iteration: 656\n",
      "Trained iteration: 657\n",
      "Trained iteration: 658\n",
      "Trained iteration: 659\n",
      "Trained iteration: 660\n",
      "Trained iteration: 661\n",
      "Trained iteration: 662\n",
      "Trained iteration: 663\n",
      "Trained iteration: 664\n",
      "Trained iteration: 665\n",
      "Trained iteration: 666\n",
      "Trained iteration: 667\n",
      "Trained iteration: 668\n",
      "Trained iteration: 669\n",
      "Trained iteration: 670\n",
      "Trained iteration: 671\n",
      "Trained iteration: 672\n",
      "Trained iteration: 673\n",
      "Trained iteration: 674\n",
      "Trained iteration: 675\n",
      "Trained iteration: 676\n",
      "Trained iteration: 677\n",
      "Trained iteration: 678\n",
      "Trained iteration: 679\n",
      "Trained iteration: 680\n",
      "Trained iteration: 681\n",
      "Trained iteration: 682\n",
      "Trained iteration: 683\n",
      "Trained iteration: 684\n",
      "Trained iteration: 685\n",
      "Trained iteration: 686\n",
      "Trained iteration: 687\n",
      "Trained iteration: 688\n",
      "Trained iteration: 689\n",
      "Trained iteration: 690\n",
      "Trained iteration: 691\n",
      "Trained iteration: 692\n",
      "Trained iteration: 693\n",
      "Trained iteration: 694\n",
      "Trained iteration: 695\n",
      "Trained iteration: 696\n",
      "Trained iteration: 697\n",
      "Trained iteration: 698\n",
      "Trained iteration: 699\n",
      "Trained iteration: 700\n",
      "Trained iteration: 701\n",
      "Trained iteration: 702\n",
      "Trained iteration: 703\n",
      "Trained iteration: 704\n",
      "Trained iteration: 705\n",
      "Trained iteration: 706\n",
      "Trained iteration: 707\n",
      "Trained iteration: 708\n",
      "Trained iteration: 709\n",
      "Trained iteration: 710\n",
      "Trained iteration: 711\n",
      "Trained iteration: 712\n",
      "Trained iteration: 713\n",
      "Trained iteration: 714\n",
      "Trained iteration: 715\n",
      "Trained iteration: 716\n",
      "Trained iteration: 717\n",
      "Trained iteration: 718\n",
      "Trained iteration: 719\n",
      "Trained iteration: 720\n",
      "Trained iteration: 721\n",
      "Trained iteration: 722\n",
      "Trained iteration: 723\n",
      "Trained iteration: 724\n",
      "Trained iteration: 725\n",
      "Trained iteration: 726\n",
      "Trained iteration: 727\n",
      "Trained iteration: 728\n",
      "Trained iteration: 729\n",
      "Trained iteration: 730\n",
      "Trained iteration: 731\n",
      "Trained iteration: 732\n",
      "Trained iteration: 733\n",
      "Trained iteration: 734\n",
      "Trained iteration: 735\n",
      "Trained iteration: 736\n",
      "Trained iteration: 737\n",
      "Trained iteration: 738\n",
      "Trained iteration: 739\n",
      "Trained iteration: 740\n",
      "Trained iteration: 741\n",
      "Trained iteration: 742\n",
      "Trained iteration: 743\n",
      "Trained iteration: 744\n",
      "Trained iteration: 745\n",
      "Trained iteration: 746\n",
      "Trained iteration: 747\n",
      "Trained iteration: 748\n",
      "Trained iteration: 749\n",
      "Trained iteration: 750\n",
      "Trained iteration: 751\n",
      "Trained iteration: 752\n",
      "Trained iteration: 753\n",
      "Trained iteration: 754\n",
      "Trained iteration: 755\n",
      "Trained iteration: 756\n",
      "Trained iteration: 757\n",
      "Trained iteration: 758\n",
      "Trained iteration: 759\n",
      "Trained iteration: 760\n",
      "Trained iteration: 761\n",
      "Trained iteration: 762\n",
      "Trained iteration: 763\n",
      "Trained iteration: 764\n",
      "Trained iteration: 765\n",
      "Trained iteration: 766\n",
      "Trained iteration: 767\n",
      "Trained iteration: 768\n",
      "Trained iteration: 769\n",
      "Trained iteration: 770\n",
      "Trained iteration: 771\n",
      "Trained iteration: 772\n",
      "Trained iteration: 773\n",
      "Trained iteration: 774\n",
      "Trained iteration: 775\n",
      "Trained iteration: 776\n",
      "Trained iteration: 777\n",
      "Trained iteration: 778\n",
      "Trained iteration: 779\n",
      "Trained iteration: 780\n",
      "Trained iteration: 781\n",
      "Trained iteration: 782\n",
      "Trained iteration: 783\n",
      "Trained iteration: 784\n",
      "Trained iteration: 785\n",
      "Trained iteration: 786\n",
      "Trained iteration: 787\n",
      "Trained iteration: 788\n",
      "Trained iteration: 789\n",
      "Trained iteration: 790\n",
      "Trained iteration: 791\n",
      "Trained iteration: 792\n",
      "Trained iteration: 793\n",
      "Trained iteration: 794\n",
      "Trained iteration: 795\n",
      "Trained iteration: 796\n",
      "Trained iteration: 797\n",
      "Trained iteration: 798\n",
      "Trained iteration: 799\n",
      "Trained iteration: 800\n",
      "Trained iteration: 801\n",
      "Trained iteration: 802\n",
      "Trained iteration: 803\n",
      "Trained iteration: 804\n",
      "Trained iteration: 805\n",
      "Trained iteration: 806\n",
      "Trained iteration: 807\n",
      "Trained iteration: 808\n",
      "Trained iteration: 809\n",
      "Trained iteration: 810\n",
      "Trained iteration: 811\n",
      "Trained iteration: 812\n",
      "Trained iteration: 813\n",
      "Trained iteration: 814\n",
      "Trained iteration: 815\n",
      "Trained iteration: 816\n",
      "Trained iteration: 817\n",
      "Trained iteration: 818\n",
      "Trained iteration: 819\n",
      "Trained iteration: 820\n",
      "Trained iteration: 821\n",
      "Trained iteration: 822\n",
      "Trained iteration: 823\n",
      "Trained iteration: 824\n",
      "Trained iteration: 825\n",
      "Trained iteration: 826\n",
      "Trained iteration: 827\n",
      "Trained iteration: 828\n",
      "Trained iteration: 829\n",
      "Trained iteration: 830\n",
      "Trained iteration: 831\n",
      "Trained iteration: 832\n",
      "Trained iteration: 833\n",
      "Trained iteration: 834\n",
      "Trained iteration: 835\n",
      "Trained iteration: 836\n",
      "Trained iteration: 837\n",
      "Trained iteration: 838\n",
      "Trained iteration: 839\n",
      "Trained iteration: 840\n",
      "Trained iteration: 841\n",
      "Trained iteration: 842\n",
      "Trained iteration: 843\n",
      "Trained iteration: 844\n",
      "Trained iteration: 845\n",
      "Trained iteration: 846\n",
      "Trained iteration: 847\n",
      "Trained iteration: 848\n",
      "Trained iteration: 849\n",
      "Trained iteration: 850\n",
      "Trained iteration: 851\n",
      "Trained iteration: 852\n",
      "Trained iteration: 853\n",
      "Trained iteration: 854\n",
      "Trained iteration: 855\n",
      "Trained iteration: 856\n",
      "Trained iteration: 857\n",
      "Trained iteration: 858\n",
      "Trained iteration: 859\n",
      "Trained iteration: 860\n",
      "Trained iteration: 861\n",
      "Trained iteration: 862\n",
      "Trained iteration: 863\n",
      "Trained iteration: 864\n",
      "Trained iteration: 865\n",
      "Trained iteration: 866\n",
      "Trained iteration: 867\n",
      "Trained iteration: 868\n",
      "Trained iteration: 869\n",
      "Trained iteration: 870\n",
      "Trained iteration: 871\n",
      "Trained iteration: 872\n",
      "Trained iteration: 873\n",
      "Trained iteration: 874\n",
      "Trained iteration: 875\n",
      "Trained iteration: 876\n",
      "Trained iteration: 877\n",
      "Trained iteration: 878\n",
      "Trained iteration: 879\n",
      "Trained iteration: 880\n",
      "Trained iteration: 881\n",
      "Trained iteration: 882\n",
      "Trained iteration: 883\n",
      "Trained iteration: 884\n",
      "Trained iteration: 885\n",
      "Trained iteration: 886\n",
      "Trained iteration: 887\n",
      "Trained iteration: 888\n",
      "Trained iteration: 889\n",
      "Trained iteration: 890\n",
      "Trained iteration: 891\n",
      "Trained iteration: 892\n",
      "Trained iteration: 893\n",
      "Trained iteration: 894\n",
      "Trained iteration: 895\n",
      "Trained iteration: 896\n",
      "Trained iteration: 897\n",
      "Trained iteration: 898\n",
      "Trained iteration: 899\n",
      "Trained iteration: 900\n",
      "Trained iteration: 901\n",
      "Trained iteration: 902\n",
      "Trained iteration: 903\n",
      "Trained iteration: 904\n",
      "Trained iteration: 905\n",
      "Trained iteration: 906\n",
      "Trained iteration: 907\n",
      "Trained iteration: 908\n",
      "Trained iteration: 909\n",
      "Trained iteration: 910\n",
      "Trained iteration: 911\n",
      "Trained iteration: 912\n",
      "Trained iteration: 913\n",
      "Trained iteration: 914\n",
      "Trained iteration: 915\n",
      "Trained iteration: 916\n",
      "Trained iteration: 917\n",
      "Trained iteration: 918\n",
      "Trained iteration: 919\n",
      "Trained iteration: 920\n",
      "Trained iteration: 921\n",
      "Trained iteration: 922\n",
      "Trained iteration: 923\n",
      "Trained iteration: 924\n",
      "Trained iteration: 925\n",
      "Trained iteration: 926\n",
      "Trained iteration: 927\n",
      "Trained iteration: 928\n",
      "Trained iteration: 929\n",
      "Trained iteration: 930\n",
      "Trained iteration: 931\n",
      "Trained iteration: 932\n",
      "Trained iteration: 933\n",
      "Trained iteration: 934\n",
      "Trained iteration: 935\n",
      "Trained iteration: 936\n",
      "Trained iteration: 937\n"
     ]
    }
   ],
   "source": [
    "# Quick test on optimizer state dict to see if I can replace a piece of the code to set optimizer state\n",
    "\n",
    "from external_train_functions import trainLoader, MNISTNet\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "mnist_net = MNISTNet().to(device)\n",
    "\n",
    "momentum = 0.4\n",
    "lr=0.01\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(mnist_net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "metrics_over_epochs = {'loss': []}\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for times, data in enumerate(trainLoader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Foward + backward + optimize\n",
    "        outputs = mnist_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Trained iteration: {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr', 'momentum', 'dampening', 'weight_decay', 'nesterov', 'maximize', 'foreach', 'differentiable'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.defaults.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr', 'momentum', 'dampening', 'weight_decay', 'nesterov', 'maximize', 'foreach', 'differentiable', 'params'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['param_groups'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('lr', 0.01), ('momentum', 0.4), ('dampening', 0), ('weight_decay', 0), ('nesterov', False), ('maximize', False), ('foreach', None), ('differentiable', False), ('params', [0, 1, 2, 3, 4, 5])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['param_groups'][0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['param_groups'][0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'momentum_buffer': tensor([[ 1.3671e-03,  1.3671e-03,  1.3671e-03,  ...,  1.3671e-03,\n",
       "            1.3671e-03,  1.3671e-03],\n",
       "          [-1.4556e-07, -1.4556e-07, -1.4556e-07,  ..., -1.4556e-07,\n",
       "           -1.4556e-07, -1.4556e-07],\n",
       "          [-3.7244e-05, -3.7244e-05, -3.7244e-05,  ..., -3.7244e-05,\n",
       "           -3.7244e-05, -3.7244e-05],\n",
       "          ...,\n",
       "          [ 3.1087e-08,  3.1087e-08,  3.1087e-08,  ...,  3.1087e-08,\n",
       "            3.1087e-08,  3.1087e-08],\n",
       "          [-1.0066e-02, -1.0066e-02, -1.0066e-02,  ..., -1.0066e-02,\n",
       "           -1.0066e-02, -1.0066e-02],\n",
       "          [ 3.7967e-03,  3.7967e-03,  3.7967e-03,  ...,  3.7967e-03,\n",
       "            3.7967e-03,  3.7967e-03]], device='cuda:0')},\n",
       " 1: {'momentum_buffer': tensor([-1.3671e-03,  1.4556e-07,  3.7244e-05, -8.0394e-03,  4.0436e-03,\n",
       "           4.9712e-17,  4.5813e-04, -9.7246e-03, -2.8577e-03, -2.3072e-06,\n",
       "           2.8912e-03, -2.0213e-03,  3.6222e-04, -2.6262e-03, -8.0052e-03,\n",
       "          -1.5372e-06, -1.9230e-03,  8.1787e-03,  4.8324e-03,  9.2669e-03,\n",
       "          -8.5011e-04, -2.8247e-03,  1.0081e-02, -2.9199e-03, -6.6029e-04,\n",
       "          -1.3458e-02,  8.5782e-03,  8.9904e-03, -2.3414e-04, -9.0834e-12,\n",
       "          -1.0845e-02,  4.9199e-13,  3.7429e-07,  4.2105e-04,  1.4026e-03,\n",
       "           4.1135e-03,  6.3028e-03, -6.3916e-03,  3.0002e-02,  4.3073e-03,\n",
       "           3.5660e-03,  1.6853e-02, -9.2147e-04,  1.8335e-06,  6.2413e-03,\n",
       "          -2.1915e-03, -5.1710e-07, -8.7058e-19, -5.4566e-03, -4.5994e-03,\n",
       "           2.5960e-04, -2.5275e-03,  8.8654e-03,  1.2638e-02,  3.1623e-03,\n",
       "          -9.8123e-03, -9.5604e-03,  7.9157e-04,  1.0083e-04, -1.2040e-03,\n",
       "           2.4070e-03, -7.4654e-03, -1.1762e-02,  1.9077e-03, -1.1090e-03,\n",
       "           8.8711e-03, -4.8625e-03, -1.8524e-05, -9.3363e-03,  1.9859e-03,\n",
       "          -4.3296e-03, -7.1992e-04, -9.1371e-03, -7.3539e-03,  7.7130e-04,\n",
       "          -5.9257e-03,  2.0095e-03,  3.8972e-03,  3.9362e-04, -6.2004e-04,\n",
       "          -1.7223e-03, -5.1858e-03, -2.2901e-04, -1.3689e-02, -6.6976e-03,\n",
       "          -1.4512e-04, -3.8454e-03,  3.4736e-03, -6.1039e-03, -1.1860e-11,\n",
       "           4.2191e-03, -4.0020e-03, -4.1326e-03,  4.3922e-04, -4.0732e-03,\n",
       "           7.1889e-03, -5.0211e-07, -2.2676e-06, -3.9788e-03, -7.1403e-06,\n",
       "           1.0419e-02, -5.6455e-09,  1.1651e-02,  7.1452e-03, -1.9177e-03,\n",
       "           9.5887e-03, -1.4507e-03, -5.0356e-03, -1.1450e-03, -3.3868e-03,\n",
       "           7.1525e-03,  6.5824e-03, -1.5909e-03, -4.8656e-03,  1.7965e-03,\n",
       "          -8.3073e-04, -7.2827e-08, -5.2750e-03, -5.5463e-03, -6.8197e-03,\n",
       "          -1.1388e-04,  5.7274e-03,  1.4608e-03,  2.6489e-04,  2.4933e-14,\n",
       "          -3.1087e-08,  1.0066e-02, -3.7967e-03], device='cuda:0')},\n",
       " 2: {'momentum_buffer': tensor([[ 1.0316e-13,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            3.4759e-08,  1.9144e-07],\n",
       "          [ 3.0371e-03, -3.2383e-08,  8.0724e-06,  ...,  4.2634e-09,\n",
       "            8.5696e-03,  2.3218e-02],\n",
       "          [-3.1520e-03,  2.2284e-09,  8.7825e-06,  ..., -4.9578e-09,\n",
       "           -6.4135e-03, -2.2905e-02],\n",
       "          ...,\n",
       "          [ 6.1730e-03,  1.9791e-09,  2.0575e-05,  ..., -2.9720e-10,\n",
       "           -3.0677e-03,  2.1474e-02],\n",
       "          [ 4.0538e-04, -6.9544e-09, -1.9184e-05,  ...,  1.8207e-10,\n",
       "            1.3644e-02,  1.4095e-02],\n",
       "          [ 2.2426e-03,  1.3926e-08, -1.5208e-05,  ...,  3.7350e-09,\n",
       "            9.7519e-03,  1.8908e-02]], device='cuda:0')},\n",
       " 3: {'momentum_buffer': tensor([ 5.7140e-08,  9.0825e-03, -9.2328e-03,  0.0000e+00, -1.2872e-06,\n",
       "           4.7411e-04,  1.5767e-03,  3.4125e-03, -1.6903e-04, -1.0807e-03,\n",
       "          -4.3897e-05,  6.7023e-06, -3.1815e-07, -1.3259e-02,  1.9711e-02,\n",
       "          -1.5470e-02,  1.0255e-02,  3.5288e-07,  2.5834e-03,  2.7168e-04,\n",
       "           5.1505e-05, -6.1403e-03,  5.7592e-04, -2.6999e-03,  9.2571e-03,\n",
       "          -3.5361e-03, -4.8407e-03,  6.7019e-03,  0.0000e+00, -5.6821e-03,\n",
       "           4.3564e-03,  2.6884e-03,  9.9872e-03,  9.3219e-03,  0.0000e+00,\n",
       "          -5.9999e-03, -4.6216e-04,  0.0000e+00,  6.5511e-04,  2.0011e-06,\n",
       "          -1.9602e-02, -1.8093e-02,  7.5932e-03,  6.3223e-03, -1.0626e-04,\n",
       "           5.8919e-04,  2.7955e-03, -1.3005e-04,  1.3256e-02,  0.0000e+00,\n",
       "           4.0307e-05, -7.6970e-03,  0.0000e+00,  0.0000e+00, -4.1302e-03,\n",
       "          -1.0249e-04, -1.2014e-02,  2.6334e-08, -3.9600e-04,  7.3459e-03,\n",
       "          -8.8582e-04,  5.8690e-03,  9.0493e-03,  1.2260e-02], device='cuda:0')},\n",
       " 4: {'momentum_buffer': tensor([[ 4.9785e-13, -4.6388e-04,  1.8196e-02,  0.0000e+00, -1.3208e-06,\n",
       "           -2.3401e-04,  1.9506e-03, -1.0145e-02,  3.4127e-06, -4.9964e-03,\n",
       "           -3.0937e-05, -8.2717e-06,  5.1415e-08,  1.6819e-02, -3.0650e-03,\n",
       "           -7.7213e-03, -2.6744e-02, -2.8995e-06,  7.9729e-03,  1.1593e-02,\n",
       "            1.0243e-02, -9.0666e-03, -7.5738e-03, -1.4583e-02, -3.0685e-03,\n",
       "           -4.6729e-04,  3.3281e-02, -6.6661e-03,  0.0000e+00, -5.1480e-03,\n",
       "           -1.3658e-02, -1.0871e-03,  1.2650e-02, -3.0738e-03,  0.0000e+00,\n",
       "           -6.1552e-03,  3.1595e-06,  0.0000e+00, -3.2876e-04,  7.5831e-07,\n",
       "            6.9225e-03,  2.7267e-03, -6.8576e-04, -2.7848e-03,  2.4190e-02,\n",
       "            1.7679e-05, -1.9823e-03, -1.2252e-03, -7.1338e-03,  0.0000e+00,\n",
       "           -4.3763e-03,  1.2228e-02,  0.0000e+00,  0.0000e+00,  2.5128e-02,\n",
       "            4.0109e-03,  1.4789e-04,  5.1396e-11,  9.6854e-04,  7.4555e-03,\n",
       "           -6.7020e-04,  5.0390e-03, -3.3657e-02, -3.3169e-02],\n",
       "          [ 9.5543e-14, -3.3848e-02,  7.0800e-04,  0.0000e+00,  5.9069e-13,\n",
       "            9.3290e-04, -2.6111e-02, -5.7347e-03, -1.3703e-04, -3.2200e-03,\n",
       "           -7.6164e-05,  4.7652e-12,  7.7097e-08, -4.5085e-03, -4.0906e-03,\n",
       "            2.0904e-03,  1.5815e-03,  3.3737e-08, -5.8542e-03,  1.7885e-03,\n",
       "           -1.5098e-02, -1.7823e-02, -2.4769e-02, -2.2505e-02, -2.3245e-03,\n",
       "           -1.2939e-02,  8.5639e-04, -1.7692e-02,  0.0000e+00, -2.2295e-03,\n",
       "            6.3008e-03, -1.9342e-05,  1.7410e-04, -2.0165e-02,  0.0000e+00,\n",
       "           -1.2161e-02,  3.3830e-07,  0.0000e+00, -2.0969e-05,  1.6020e-07,\n",
       "           -2.8153e-02, -9.8281e-03, -3.1771e-02, -4.5403e-03, -2.1014e-02,\n",
       "            3.5355e-05, -1.5443e-02,  1.0727e-09, -3.3354e-02,  0.0000e+00,\n",
       "           -2.5897e-03, -9.3962e-03,  0.0000e+00,  0.0000e+00, -1.8058e-02,\n",
       "           -2.1127e-02, -1.8681e-02,  3.3162e-11,  1.7472e-04, -8.1805e-03,\n",
       "           -1.0820e-02,  1.6422e-03, -5.4459e-02, -3.9187e-03],\n",
       "          [ 1.9276e-12,  1.7703e-02,  4.0063e-02,  0.0000e+00,  4.7476e-07,\n",
       "           -6.8807e-03,  4.7284e-02,  4.2296e-02, -7.5388e-05,  4.7665e-02,\n",
       "           -2.1676e-04,  8.4654e-07,  8.3105e-08,  8.3177e-02,  2.6172e-02,\n",
       "            5.9213e-02,  3.8876e-02, -1.5949e-06,  2.7808e-02,  3.6478e-02,\n",
       "            4.0072e-02,  6.9630e-03,  1.1860e-02,  4.1182e-02,  2.6943e-02,\n",
       "            4.8203e-03,  5.1160e-02,  5.3628e-02,  0.0000e+00,  5.4873e-02,\n",
       "            7.6623e-02,  2.0130e-02,  3.3708e-02,  1.6644e-03,  0.0000e+00,\n",
       "            4.0656e-02, -4.8127e-04,  0.0000e+00, -2.7629e-04,  1.6560e-05,\n",
       "            1.5037e-02,  3.2365e-02,  1.0623e-04,  2.8711e-03,  3.0123e-02,\n",
       "           -4.5548e-04,  1.6989e-02,  3.0852e-05,  1.7995e-02,  0.0000e+00,\n",
       "            9.9675e-03,  4.2381e-02,  0.0000e+00,  0.0000e+00,  4.9854e-02,\n",
       "            8.9621e-03,  2.6007e-02,  1.6939e-08,  5.4664e-03,  5.9004e-02,\n",
       "           -2.3030e-03,  6.6969e-02,  4.5779e-02,  1.6755e-02],\n",
       "          [ 1.8500e-11,  5.1704e-02,  5.9151e-03,  0.0000e+00,  2.4414e-07,\n",
       "            1.0444e-02,  7.2026e-02,  5.1447e-02,  3.1447e-04,  4.7032e-02,\n",
       "            1.8497e-04,  1.1405e-06,  7.7724e-08,  4.7270e-02,  7.0993e-02,\n",
       "            3.2054e-02,  9.1715e-02, -2.6977e-06,  1.3861e-02,  6.2298e-02,\n",
       "            5.0583e-02,  1.6238e-02,  5.8126e-02,  3.9492e-02,  6.2841e-02,\n",
       "            4.3448e-03,  7.9276e-03,  7.1356e-02,  0.0000e+00,  2.9794e-02,\n",
       "            1.0551e-01,  1.7929e-02,  1.6788e-02,  3.1426e-02,  0.0000e+00,\n",
       "            4.8130e-02,  3.9578e-04,  0.0000e+00,  2.1958e-04, -5.3827e-05,\n",
       "            3.3140e-02,  1.8690e-02,  1.7481e-02,  1.3775e-02,  4.0917e-02,\n",
       "            3.0367e-04,  2.1614e-02,  1.7145e-06,  9.0828e-02,  0.0000e+00,\n",
       "            2.4741e-02,  4.3042e-02,  0.0000e+00,  0.0000e+00,  1.5436e-02,\n",
       "            2.3549e-02,  4.5812e-02, -5.0183e-08,  1.0266e-03,  5.4049e-02,\n",
       "            1.8439e-02,  6.0447e-02,  1.4288e-01,  9.2948e-02],\n",
       "          [ 1.3989e-11, -1.6585e-02, -5.9422e-02,  0.0000e+00,  2.8308e-12,\n",
       "            2.0438e-03, -6.7979e-02, -5.2188e-02,  1.5853e-06, -6.8718e-02,\n",
       "            5.9967e-05,  1.6768e-09,  1.1619e-07, -1.0545e-01, -7.6435e-02,\n",
       "           -9.6640e-02, -6.2402e-02,  4.3731e-10, -3.4325e-02, -6.2855e-02,\n",
       "           -8.0865e-02,  2.2412e-03,  3.3290e-04, -3.4571e-02, -8.9376e-02,\n",
       "           -7.5560e-05, -1.0692e-01, -7.4128e-02,  0.0000e+00, -6.8467e-02,\n",
       "           -1.3755e-01, -3.3511e-02, -6.8430e-02,  6.9759e-03,  0.0000e+00,\n",
       "           -2.6672e-02,  1.7160e-05,  0.0000e+00,  6.0479e-06,  2.5542e-08,\n",
       "           -1.1913e-02, -3.0029e-02, -4.7318e-03,  2.8302e-04, -6.0731e-02,\n",
       "            1.0719e-03, -1.3412e-02, -8.8414e-09, -1.8479e-02,  0.0000e+00,\n",
       "           -1.0412e-02, -6.8179e-02,  0.0000e+00,  0.0000e+00, -7.8296e-02,\n",
       "            8.7616e-03, -1.4942e-02,  9.4444e-11, -5.7636e-03, -1.0197e-01,\n",
       "            3.5057e-03, -1.2611e-01, -4.9878e-02, -2.3052e-02],\n",
       "          [ 3.5112e-12,  1.0256e-02,  1.7381e-02,  0.0000e+00,  5.5690e-07,\n",
       "           -6.0181e-03,  6.4397e-03,  9.1962e-04, -2.4841e-04,  8.9802e-03,\n",
       "            1.8270e-05,  6.9623e-06, -1.4025e-06,  2.0858e-02,  3.4880e-04,\n",
       "            2.3053e-02, -1.0518e-04,  3.6815e-06,  8.4862e-03, -1.2443e-02,\n",
       "            2.1796e-02,  7.3052e-03,  4.6984e-03,  2.5102e-02, -3.9527e-03,\n",
       "            7.8771e-03,  1.1416e-02,  1.7243e-03,  0.0000e+00,  2.0787e-02,\n",
       "            1.5599e-02,  1.8408e-03,  1.0465e-02,  5.0440e-03,  0.0000e+00,\n",
       "            1.6776e-02,  4.7903e-05,  0.0000e+00,  2.3567e-04,  2.9858e-05,\n",
       "            2.6080e-02,  2.5185e-02,  2.2454e-02,  3.5570e-03,  2.9040e-02,\n",
       "           -5.6914e-04,  9.3313e-03,  1.2004e-03, -4.5803e-03,  0.0000e+00,\n",
       "            5.8465e-03,  1.6525e-02,  0.0000e+00,  0.0000e+00,  3.0535e-02,\n",
       "            2.9243e-02,  8.0083e-03,  6.2870e-10,  2.0872e-03,  6.0444e-03,\n",
       "            6.4745e-03,  3.8470e-02, -1.3873e-03, -1.3307e-02],\n",
       "          [ 2.7871e-15,  9.8300e-03, -1.1336e-02,  0.0000e+00,  1.5148e-10,\n",
       "            1.2146e-03, -2.8278e-03, -1.3152e-02,  9.7577e-06,  7.1624e-04,\n",
       "           -7.4138e-05,  6.3157e-08,  3.2080e-08, -5.7049e-03, -7.9845e-03,\n",
       "           -4.1409e-03, -3.6725e-03,  3.2054e-09, -2.8671e-03, -4.2015e-03,\n",
       "            8.6103e-03, -5.2595e-04,  1.5354e-02, -5.9007e-03,  1.3040e-03,\n",
       "            2.2506e-03,  1.7231e-03, -6.9096e-03,  0.0000e+00, -1.6967e-02,\n",
       "           -8.2591e-03, -6.6050e-03, -3.1752e-03,  5.3777e-03,  0.0000e+00,\n",
       "           -4.9923e-03,  1.8947e-06,  0.0000e+00,  5.1824e-05,  1.2370e-09,\n",
       "            1.3056e-02, -5.0714e-03,  6.3962e-03, -5.0507e-03,  5.5480e-03,\n",
       "           -1.1278e-03, -7.5265e-03,  8.0373e-06,  2.1407e-03,  0.0000e+00,\n",
       "            1.5786e-03,  6.4861e-03,  0.0000e+00,  0.0000e+00, -1.9579e-03,\n",
       "           -4.8995e-04,  1.3785e-04,  1.8770e-13, -4.8802e-03, -6.5429e-03,\n",
       "            2.8688e-03, -4.7161e-03,  3.9329e-03, -3.8028e-03],\n",
       "          [-9.9333e-08, -2.7050e-02, -2.8133e-03,  0.0000e+00,  1.6922e-09,\n",
       "            8.0798e-05, -4.4566e-03, -2.7324e-02,  4.4852e-05, -1.8861e-02,\n",
       "            2.2385e-06,  1.0800e-08,  2.0916e-09, -5.7762e-02, -4.1063e-03,\n",
       "           -2.9852e-02, -3.0974e-02,  4.1398e-09, -3.0259e-02, -1.2605e-02,\n",
       "           -1.2388e-02, -1.9356e-02, -1.6314e-02, -3.9114e-02,  5.4968e-04,\n",
       "           -1.8136e-02,  2.2320e-03, -5.0971e-02,  0.0000e+00, -4.3085e-02,\n",
       "           -1.8730e-02, -4.2970e-03, -2.1153e-03,  5.3703e-03,  0.0000e+00,\n",
       "           -4.6051e-02, -9.6136e-06,  0.0000e+00,  6.2442e-06,  2.0306e-07,\n",
       "           -3.7174e-02, -1.8717e-02, -3.6396e-03, -1.2197e-02, -1.5733e-02,\n",
       "            2.4222e-05, -1.4635e-02,  9.2648e-09, -1.8331e-02,  0.0000e+00,\n",
       "           -1.6882e-02, -4.1129e-02,  0.0000e+00,  0.0000e+00, -1.8133e-03,\n",
       "           -3.2102e-02, -3.7283e-02,  1.2356e-08,  1.4215e-04, -3.1755e-02,\n",
       "           -7.7762e-03, -1.7547e-02, -3.9873e-02, -1.5719e-02],\n",
       "          [ 7.1779e-11, -1.8215e-02, -2.4251e-02,  0.0000e+00,  4.2064e-08,\n",
       "           -2.6603e-03, -3.0949e-02, -3.1007e-04,  6.2338e-04, -2.0779e-02,\n",
       "            1.2236e-04, -8.7279e-07,  9.6177e-07, -2.6832e-02, -5.6123e-03,\n",
       "           -7.9688e-03, -2.3171e-02,  3.4459e-06, -1.6291e-03, -2.8703e-02,\n",
       "           -2.7699e-02,  3.8410e-03, -4.3629e-02, -1.1050e-02,  3.2899e-03,\n",
       "            3.0446e-03, -6.7921e-03,  4.7858e-04,  0.0000e+00,  3.1262e-03,\n",
       "           -4.6170e-02,  1.7091e-03,  3.5741e-03, -1.9641e-02,  0.0000e+00,\n",
       "           -3.2488e-02,  1.2625e-05,  0.0000e+00,  1.0707e-04,  5.6169e-06,\n",
       "           -3.8917e-02, -3.3321e-02, -8.5912e-03,  1.3324e-03, -4.4229e-02,\n",
       "            1.2848e-04, -4.0217e-03, -1.6078e-05, -3.1158e-02,  0.0000e+00,\n",
       "           -1.2918e-02, -2.6388e-02,  0.0000e+00,  0.0000e+00, -3.4792e-02,\n",
       "           -3.4424e-02, -3.1984e-02,  2.5310e-09, -7.4959e-04,  1.2778e-03,\n",
       "           -1.1485e-02, -4.2840e-02, -3.0251e-02, -1.8577e-02],\n",
       "          [ 9.9223e-08,  6.6686e-03,  1.5558e-02,  0.0000e+00,  1.0907e-09,\n",
       "            1.0774e-03,  4.6235e-03,  1.4191e-02, -5.3663e-04,  1.2180e-02,\n",
       "            1.0197e-05,  1.1962e-07,  9.8308e-10,  3.2129e-02,  3.7795e-03,\n",
       "            2.9912e-02,  1.4896e-02,  2.3283e-08,  1.6807e-02,  8.6501e-03,\n",
       "            4.7460e-03,  1.0183e-02,  1.9151e-03,  2.1948e-02,  3.7942e-03,\n",
       "            9.2800e-03,  5.1143e-03,  2.9179e-02,  0.0000e+00,  2.7318e-02,\n",
       "            2.0338e-02,  3.9100e-03, -3.6389e-03, -1.2978e-02,  0.0000e+00,\n",
       "            2.2956e-02,  1.2022e-05,  0.0000e+00, -4.2264e-07,  6.4371e-07,\n",
       "            2.1922e-02,  1.8000e-02,  2.9823e-03,  2.7545e-03,  1.1888e-02,\n",
       "            5.7119e-04,  9.0858e-03,  2.8663e-07,  2.0720e-03,  0.0000e+00,\n",
       "            5.0444e-03,  2.4430e-02,  0.0000e+00,  0.0000e+00,  1.3965e-02,\n",
       "            1.3616e-02,  2.2777e-02,  1.7549e-08,  1.5277e-03,  2.0613e-02,\n",
       "            1.7664e-03,  1.8646e-02,  1.6916e-02,  1.8435e-03]], device='cuda:0')},\n",
       " 5: {'momentum_buffer': tensor([ 0.0001, -0.0072,  0.0197,  0.0255, -0.0276,  0.0047, -0.0010, -0.0112,\n",
       "          -0.0098,  0.0069], device='cuda:0')}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['state'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_opt_state = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/edwardsb/repositories/nnUNet/nnunet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################################################################\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "2024-02-13 18:18:06.275960: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-13 18:18:09.586149: Unable to plot network architecture:\n",
      "2024-02-13 18:18:09.587511: No module named 'hiddenlayer'\n",
      "2024-02-13 18:18:09.603727: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-13 18:18:09.604737: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-13 18:18:09.610043: \n",
      "\n",
      "2024-02-13 18:18:09.626694: \n",
      "epoch:  0\n",
      "2024-02-13 18:24:54.962004: train loss : -0.4442\n",
      "2024-02-13 18:25:13.483093: validation loss: -0.6574\n",
      "2024-02-13 18:25:13.486141: Average global foreground Dice: [0.9121, 0.9299, 0.9439]\n",
      "2024-02-13 18:25:13.486916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edwardsb/repositories/nnUNet/nnunet/training/network_training/nnUNetTrainer.py:712: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  global_dc_per_class = [i for i in [2 * i / (2 * i + j + k) for i, j, k in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 18:25:13.868807: lr: 0.005359\n",
      "2024-02-13 18:25:13.869843: This epoch took 424.242370 s\n",
      "\n",
      "2024-02-13 18:25:13.870560: \n",
      "epoch:  1\n",
      "2024-02-13 18:30:12.064173: train loss : -0.6635\n",
      "2024-02-13 18:30:30.581601: validation loss: -0.6981\n",
      "2024-02-13 18:30:30.583606: Average global foreground Dice: [0.9414, 0.9499, 0.9582]\n",
      "2024-02-13 18:30:30.584514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2024-02-13 18:30:31.020232: lr: 0.0\n",
      "2024-02-13 18:30:31.021571: This epoch took 317.150438 s\n",
      "\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model_dir = '/raid/edwardsb/projects/RANO/NNUnetExperiments/TestOutput/models'\n",
    "mnist_model_name = 'MNIST_TEST'\n",
    "config_path = '/raid/edwardsb/projects/RANO/NNUnetExperiments/TestConfigs/mnist_config.yaml'\n",
    "\n",
    "mnist_initial_model_path = get_mnist_model_path(model_dir=mnist_model_dir, model_name=mnist_model_name, model_tag='init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torchvision import datasets, transforms\\nimport torch.utils.data as dset\\n\\n# Transform\\ntransform = transforms.Compose(\\n    [transforms.ToTensor(),\\n     transforms.Normalize((0.5,), (0.5,)),]\\n)\\n\\n\\n# Data\\ntrainSet = datasets.MNIST(root=\\'MNIST\\', download=True, train=True, transform=transform)\\ntestSet = datasets.MNIST(root=\\'MNIST\\', download=True, train=False, transform=transform)\\ntrainLoader = dset.DataLoader(trainSet, batch_size=64, shuffle=True)\\ntestLoader = dset.DataLoader(testSet, batch_size=64, shuffle=False)\\n\\nfor batch in trainLoader:\\n    print(len(batch))\\n    print(batch[0].shape)\\n    print(batch[1].shape)\\n    print(f\"Batch is shaped: {batch.shape}\")\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING\n",
    "\"\"\"\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as dset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "\n",
    "\n",
    "# Data\n",
    "trainSet = datasets.MNIST(root='MNIST', download=True, train=True, transform=transform)\n",
    "testSet = datasets.MNIST(root='MNIST', download=True, train=False, transform=transform)\n",
    "trainLoader = dset.DataLoader(trainSet, batch_size=64, shuffle=True)\n",
    "testLoader = dset.DataLoader(testSet, batch_size=64, shuffle=False)\n",
    "\n",
    "for batch in trainLoader:\n",
    "    print(len(batch))\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    print(f\"Batch is shaped: {batch.shape}\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's get some basic deterministic PyTorch model to play with \n",
    "Copied below from: https://www.kaggle.com/code/bminixhofer/deterministic-neural-networks-using-pytorch\n",
    "\"\"\"\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef get_mnist_model_path(model_dir, model_name, model_tag):\\n    return os.path.join(model_dir, model_name + f, '_{model_tag}' + '.pt')\\n\\n\\n\\n# You will see below that the model saves every 100 iterations and at the last iteration in an epoch. There are 938 batches in the train loader,\\n# So the iterations for saving are: 99, 199, 299, ..., 899, 937\\n    \\n# number batches is 938 (confirmed by getting length of loader when in memory below    \\n    \\ndef mnist_model_paths(model_dir, model_name, start_epoch, epochs):\\n    # maybe won't end up using this\\n    all_epochs = range(start_epoch, start_epoch + epochs)\\n    paths = []\\n    for epoch in all_epochs:\\n        # This is hard coded and determined by the length of the loader () and the fact model checkpoints get saved after every 100 iterations and after the last iteration\\n        for iter in [99, 199, 299, 399, 499, 599, 699, 799, 899, 937]:\\n            paths.append(get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{iter}'))\\n\\n    return paths\\n\\n\\ndef mnist_round_to_model_startpath(model_dir, model_name, epochs, round):\\n    # recall the value of round (since 0 indexed) is equal to how many rounds have already trained\\n    epoch = round * epochs - 1   # one less than the number of epochs already trained (start epoch - 1)\\n    return get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{937}')\\n\\n\\ndef mnist_round_to_model_endpath(model_dir, model_name, epochs, round):\\n    epoch = round * epochs - 1 + epochs   # start_epoch + epochs\\n    return get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{937}')\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_mnist_model_path(model_dir, model_name, model_tag):\n",
    "    return os.path.join(model_dir, model_name + f, '_{model_tag}' + '.pt')\n",
    "\n",
    "\n",
    "\n",
    "# You will see below that the model saves every 100 iterations and at the last iteration in an epoch. There are 938 batches in the train loader,\n",
    "# So the iterations for saving are: 99, 199, 299, ..., 899, 937\n",
    "    \n",
    "# number batches is 938 (confirmed by getting length of loader when in memory below    \n",
    "    \n",
    "def mnist_model_paths(model_dir, model_name, start_epoch, epochs):\n",
    "    # maybe won't end up using this\n",
    "    all_epochs = range(start_epoch, start_epoch + epochs)\n",
    "    paths = []\n",
    "    for epoch in all_epochs:\n",
    "        # This is hard coded and determined by the length of the loader () and the fact model checkpoints get saved after every 100 iterations and after the last iteration\n",
    "        for iter in [99, 199, 299, 399, 499, 599, 699, 799, 899, 937]:\n",
    "            paths.append(get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{iter}'))\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def mnist_round_to_model_startpath(model_dir, model_name, epochs, round):\n",
    "    # recall the value of round (since 0 indexed) is equal to how many rounds have already trained\n",
    "    epoch = round * epochs - 1   # one less than the number of epochs already trained (start epoch - 1)\n",
    "    return get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{937}')\n",
    "\n",
    "\n",
    "def mnist_round_to_model_endpath(model_dir, model_name, epochs, round):\n",
    "    epoch = round * epochs - 1 + epochs   # start_epoch + epochs\n",
    "    return get_mnist_model_path(model_dir=model_dir, model_name=model_name, model_tag=f'epoch_{epoch}_iter_{937}')\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model_dir = '/raid/edwardsb/projects/RANO/NNUnetExperiments/mnist_model_tests/model_checkpoints'\n",
    "initial_mnist_model_path = get_mnist_model_path(model_dir=mnist_model_dir, model_name=mnist_model_name,model_tag='initial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_extract_info_from_loaded_checkpoint(checkpoint):\n",
    "    \"\"\"\n",
    "    Takes checkpoint object resulting from torch.load on a checkpoint file, then returns a dictionary\n",
    "    with the following:\n",
    "    {\n",
    "    'model_state_dict': model_state_dict,\n",
    "    'optimizer_state_dict': optimizer_state_dict,\n",
    "    'metrics': metrics\n",
    "\n",
    "    }\n",
    "\n",
    "    The metrics should be in a format OpenFL uses for aggregation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    extracted_dict = {\n",
    "                    'model_state_dict': checkpoint['model_state_dict'],\n",
    "                    'optimizer_state_dict': checkpoint['optimizer_state_dict'],\n",
    "                    'metrics': {'loss': checkpoint['loss'], 'validation': checkpoint['validation']}, \n",
    "                    'other': {'epoch': checkpoint['epoch'],\n",
    "                              'lr_scheduler_state_dict': checkpoint['lr_scheduler_state_dict'],\n",
    "                              'plot_stuff': checkpoint['plot_stuff'],\n",
    "                              'best_stuff': checkpoint['best_stuff']\n",
    "                             }\n",
    "                     }\n",
    "    \n",
    "    return extracted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['written_using_a_mount.txt', 'delete_me.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ch_pt_taskrunner \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpointPyTorchTaskRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmnist_model_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel_init_fpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_mnist_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mextract_info_from_loaded_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmnist_extract_info_from_loaded_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mround_to_model_startpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmnist_round_to_model_startpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mround_to_model_endpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmnist_round_to_model_endpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdummy_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/be-SATGOpenFL/openfl/federated/task/runner_checkpoint_pytorch.py:84\u001b[0m, in \u001b[0;36mCheckpointPyTorchTaskRunner.__init__\u001b[0;34m(self, model_dir, model_init_fpath, extract_info_from_loaded_checkpoint, config, config_path, round_to_model_startpath, round_to_model_endpath, stardardized_model_state_dict_key, standardized_optimizer_state_dict_key, standardized_metrics_key, training_sample_count_key, evaluation_sample_count_key, load_save_device, training_device, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_save_device \u001b[38;5;241m=\u001b[39m load_save_device\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_device \u001b[38;5;241m=\u001b[39m training_device\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_native\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_init_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_save_device\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_tensorkeys_for_function \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_tensorkeys_for_functions()\n",
      "File \u001b[0;32m~/repositories/be-SATGOpenFL/openfl/federated/task/runner_checkpoint_pytorch.py:135\u001b[0m, in \u001b[0;36mCheckpointPyTorchTaskRunner.load_native\u001b[0;34m(self, filepath, map_location, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_save_device)\n\u001b[1;32m    134\u001b[0m pickle_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filepath, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m--> 135\u001b[0m standardized_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_info_from_loaded_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(standardized_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstardardized_model_state_dict_key])\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(standardized_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstandardized_optimizer_state_dict_key])\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mmnist_extract_info_from_loaded_checkpoint\u001b[0;34m(checkpoint)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmnist_extract_info_from_loaded_checkpoint\u001b[39m(checkpoint):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Takes checkpoint object resulting from torch.load on a checkpoint file, then returns a dictionary\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    with the following:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    The metrics should be in a format OpenFL uses for aggregation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     extracted_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m---> 21\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m]}, \n\u001b[1;32m     22\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     23\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_stuff\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_stuff\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     25\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_stuff\u001b[39m\u001b[38;5;124m'\u001b[39m: checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_stuff\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m                              }\n\u001b[1;32m     27\u001b[0m                      }\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_dict\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "test_path = '/home/edwardsb/temp/delete_me.pkl'\n",
    "sesser = {'A': 4, 'B': 19}\n",
    "\n",
    "with open(test_path, 'wb') as _file:\n",
    "    pkl.dump(sesser, _file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 4, 'B': 19}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(test_path, 'rb') as _file:\n",
    "    recover = pkl.load(_file)\n",
    "\n",
    "recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, {'A': 7})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# No longer needed, to save off the configuration\n",
    "##############################\n",
    "\n",
    "if False:\n",
    "\n",
    "    # config will generally come from file so I will do so here as a yaml file\n",
    "    class Configuration():\n",
    "        def __init__(self, config_dict):\n",
    "            for key, value in config_dict.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "\n",
    "    config_dict = {'lr': 0.002, \n",
    "                'momentum': 0.9, \n",
    "                'criterion': 'nll_loss', \n",
    "                'optimizer': 'sgd', \n",
    "                'model_dir': model_dir, \n",
    "                'model_name': model_name}\n",
    "\n",
    "    write_json(obj=config_dict, path=config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# no longer needed, to save an initial model (Note here I use specifics regarding how checkpoints are saved for the task runner we are using)\n",
    "###########################################################\n",
    "if True:\n",
    "    initial_model = MNISTNet().to('cpu')\n",
    "\n",
    "    # grab the config off disk\n",
    "    config = load_json(config_path)\n",
    "    lr = config['lr']\n",
    "    momentum = config['momentum']\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(initial_model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    checkpoint_dict = {\n",
    "        'model_state_dict': initial_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "\n",
    "\n",
    "    }\n",
    "    torch.save(checkpoint_dict, initial_mnist_model_path)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/edwardsb/projects/RANO/NNUnetExperiments/TestOutput/models/MNIST_TEST_init.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Looking into optimizer state\n",
    "start_path = '/raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_START.model'\n",
    "\n",
    "starting_opt_state = torch.load(start_path)['optimizer_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_opt_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starting_opt_state['param_groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_opt_state['param_groups'][0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# testing the runner\n",
    "#################################\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/edwardsb/repositories/be-SATGOpenFL/openfl/federated/task')\n",
    "\n",
    "from runner_weightsonly_checkpoint_pytorch import WeightsOnlyPyTorchCheckpointTaskRunner\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['nnUNet_raw_data_base']='/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base'\n",
    "os.environ['nnUNet_preprocessed']='/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed'\n",
    "os.environ['RESULTS_FOLDER']='/raid/edwardsb/projects/RANO/NNUnetModels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model'\n",
    "\n",
    "start_path = '/raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_START.model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Let's get an example tensor_dict\\nfrom openfl.federated.task.runner_pt_utils import to_cpu_numpy\\nimport torch\\nmodel_state = torch.load(checkpoint_path)['state_dict']\\nsome_tensor_dict = to_cpu_numpy(model_state)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Let's get an example tensor_dict\n",
    "from openfl.federated.task.runner_pt_utils import to_cpu_numpy\n",
    "import torch\n",
    "model_state = torch.load(checkpoint_path)['state_dict']\n",
    "some_tensor_dict = to_cpu_numpy(model_state)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "sys.path.append('/home/edwardsb/repositories/be-SATGOpenFL/openf/federated/task')\n",
    "from runner_pt_utils import DummyDataLoader\n",
    "\n",
    "dummy_loader = DummyDataLoader(feature_shape=[1, 28, 28], \n",
    "                               training_data_size=938, \n",
    "                               valid_data_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = WeightsOnlyPyTorchCheckpointTaskRunner(data_loader=dummy_loader, \n",
    "                                                checkpoint_in_path=checkpoint_path,\n",
    "                                                checkpoint_out_path=checkpoint_path, \n",
    "                                                checkpoint_init_path=start_path,\n",
    "                                                device='cuda', \n",
    "                                                gpu_num_string='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_from_tensordict(tensordict):\n",
    "    print(tensordict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize to a starting point (replace_checkpoint does so with entire file replacement inluding any model, opt, and metric state)\n",
    "runner.replace_checkpoint(path_to_replacement=start_path)\n",
    "\n",
    "# Get model and optimizert state from the starting checkpoint\n",
    "starting_tensor_dict = runner.get_tensor_dict(with_opt_vars=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_tensor_dict['__opt_state_needed'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# NO NEED TO RUN AGAIN SO COMMENTING OUT - Reset the epoch part of the START checkpoint\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "\n",
    "import torch\n",
    "chckpt = torch.load(start_path)\n",
    "print(chckpt['epoch'])\n",
    "chckpt['epoch'] = 1\n",
    "torch.save(chckpt, start_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.checkpoint_in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_with_opt_setting = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2024-02-22 11:26:00.171072: loading checkpoint /raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model train= True\n",
      "2024-02-22 11:26:00.585728: lr: 0.009991\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-22 11:26:08.945627: Unable to plot network architecture:\n",
      "2024-02-22 11:26:08.946881: No module named 'hiddenlayer'\n",
      "2024-02-22 11:26:08.947994: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-22 11:26:08.948534: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-22 11:26:08.952352: \n",
      "\n",
      "2024-02-22 11:26:08.953465: \n",
      "epoch:  1\n",
      "2024-02-22 11:34:17.625320: train loss : -0.6617\n",
      "2024-02-22 11:34:45.088078: validation loss: -0.6883\n",
      "2024-02-22 11:34:45.093715: Average global foreground Dice: [0.9434, 0.9533, 0.9666]\n",
      "2024-02-22 11:34:45.094754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edwardsb/repositories/nnUNet/nnunet/training/network_training/nnUNetTrainer.py:712: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  global_dc_per_class = [i for i in [2 * i / (2 * i + j + k) for i, j, k in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 11:34:45.552419: lr: 0.009982\n",
      "2024-02-22 11:34:45.627603: saving checkpoint...\n",
      "2024-02-22 11:34:46.206264: done, saving took 0.65 seconds\n",
      "2024-02-22 11:34:46.210786: This epoch took 517.256598 s\n",
      "\n",
      "2024-02-22 11:34:46.242543: saving checkpoint...\n",
      "2024-02-22 11:34:46.764384: done, saving took 0.55 seconds\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": [
    "e2_DB, _ = runner.train(col_name='BTest', \n",
    "                            round_num=0, \n",
    "                            input_tensor_dict=starting_tensor_dict, \n",
    "                            epochs=1, \n",
    "                            testing_with_opt_setting=testing_with_opt_setting)\n",
    "e2_tdict_1 = runner.get_tensor_dict(with_opt_vars=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_folder = '/raid/edwardsb/projects/RANO/NNUnetExperiments/TestOutput/pickled_tensor_dicts'\n",
    "\n",
    "e2_tdict_1_path = os.path.join(test_results_folder, 'e2_tdict_1.pkl')\n",
    "\n",
    "def serialize(obj, path):\n",
    "    with open(path, 'wb') as _file:\n",
    "        pkl.dump(obj, _file)\n",
    "\n",
    "\n",
    "serialize(e2_tdict_1, e2_tdict_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2024-02-22 11:34:51.279398: loading checkpoint /raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model train= True\n",
      "2024-02-22 11:34:51.720019: lr: 0.009982\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-22 11:35:10.929375: Unable to plot network architecture:\n",
      "2024-02-22 11:35:10.931649: No module named 'hiddenlayer'\n",
      "2024-02-22 11:35:10.933793: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-22 11:35:10.934657: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-22 11:35:10.939605: \n",
      "\n",
      "2024-02-22 11:35:10.942443: \n",
      "epoch:  2\n",
      "2024-02-22 11:43:23.609771: train loss : -0.6870\n",
      "2024-02-22 11:43:51.175293: validation loss: -0.7026\n",
      "2024-02-22 11:43:51.177086: Average global foreground Dice: [0.958, 0.9606, 0.973]\n",
      "2024-02-22 11:43:51.178677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2024-02-22 11:43:51.663271: lr: 0.009973\n",
      "2024-02-22 11:43:51.972095: saving checkpoint...\n",
      "2024-02-22 11:43:52.603886: done, saving took 0.94 seconds\n",
      "2024-02-22 11:43:52.607473: This epoch took 521.661152 s\n",
      "\n",
      "2024-02-22 11:43:52.644544: saving checkpoint...\n",
      "2024-02-22 11:43:53.169245: done, saving took 0.56 seconds\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": [
    "e2_tdict_1['__opt_state_needed'] = True\n",
    "e3_DB, _ = runner.train(col_name='BTest', \n",
    "                            round_num=1, \n",
    "                            input_tensor_dict=e2_tdict_1, \n",
    "                            epochs=1, \n",
    "                            testing_with_opt_setting=testing_with_opt_setting)\n",
    "e3_tdict_1 = runner.get_tensor_dict(with_opt_vars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_tdict_1_path = os.path.join(test_results_folder, 'e3_tdict_1.pkl')\n",
    "\n",
    "serialize(e3_tdict_1, e3_tdict_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2024-02-22 11:43:57.842087: loading checkpoint /raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model train= True\n",
      "2024-02-22 11:43:58.290148: lr: 0.009973\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-22 11:44:09.324583: Unable to plot network architecture:\n",
      "2024-02-22 11:44:09.326024: No module named 'hiddenlayer'\n",
      "2024-02-22 11:44:09.326736: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-22 11:44:09.327243: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-22 11:44:09.330489: \n",
      "\n",
      "2024-02-22 11:44:09.331404: \n",
      "epoch:  3\n",
      "2024-02-22 11:52:25.396589: train loss : -0.6643\n",
      "2024-02-22 11:52:52.560192: validation loss: -0.6939\n",
      "2024-02-22 11:52:52.561976: Average global foreground Dice: [0.9493, 0.9568, 0.9696]\n",
      "2024-02-22 11:52:52.563466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2024-02-22 11:52:53.015198: lr: 0.009964\n",
      "2024-02-22 11:52:53.015975: This epoch took 523.684020 s\n",
      "\n",
      "2024-02-22 11:52:53.094078: saving checkpoint...\n",
      "2024-02-22 11:52:53.629027: done, saving took 0.61 seconds\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": [
    "starting_tensor_dict['__opt_state_needed'] = True\n",
    "e2_DB_2, _ = runner.train(col_name='BTest', \n",
    "                            round_num=0, \n",
    "                            input_tensor_dict=starting_tensor_dict, \n",
    "                            epochs=1, \n",
    "                            testing_with_opt_setting=testing_with_opt_setting)\n",
    "e2_tdict_2 = runner.get_tensor_dict(with_opt_vars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_tdict_2_path = os.path.join(test_results_folder, 'e2_tdict_2.pkl')\n",
    "\n",
    "serialize(e2_tdict_2, e2_tdict_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tensordicts(t1, t2):\n",
    "    results_dict = {}\n",
    "    for k in t1:\n",
    "        if k != '__opt_state_needed':\n",
    "            results_dict[k] = np.linalg.norm(t1[k] - t2[k])\n",
    "\n",
    "    return np.sum(list(results_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.735441797430084"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_tensordicts(starting_tensor_dict, e2_tdict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.31696422676187"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_tensordicts(e2_tdict_1, e2_tdict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.600728703224306"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_tensordicts(e2_tdict_1, e3_tdict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.944277215251027"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_tensordicts(e2_tdict_2, e3_tdict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "TensorKey(tensor_name='train_loss', origin='BTest', round_number='0', report=True, tags=('metric',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# What about metrics?\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys_round_0:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: metric value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me2_DB[key]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: TensorKey(tensor_name='train_loss', origin='BTest', round_number='0', report=True, tags=('metric',))"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from openfl.utilities import TensorKey\n",
    "tags = ('trained',)\n",
    "col_name = 'BTest'\n",
    "origin = col_name\n",
    "\n",
    "keys_round_0 = [TensorKey(metric_name, origin, '0', True, ('metric',)) for metric_name in ['train_loss', 'val_eval']]\n",
    "\n",
    "# What about metrics?\n",
    "for key in keys_round_0:\n",
    "    print(f\"Key: {key}: metric value: {e2_DB[key]}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorKey(tensor_name='train_loss', origin='BTest', round_number=0, report=True, tags=('metric',)),\n",
       "  array(-0.4103565, dtype=float32)),\n",
       " (TensorKey(tensor_name='val_eval', origin='BTest', round_number=0, report=True, tags=('metric',)),\n",
       "  array(0.92396351))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e2_DB.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorKey(tensor_name='train_loss', origin='BTest', round_number=1, report=True, tags=('metric',)),\n",
       "  array(-0.6609627, dtype=float32)),\n",
       " (TensorKey(tensor_name='val_eval', origin='BTest', round_number=1, report=True, tags=('metric',)),\n",
       "  array(0.95411969))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e3_DB.items())[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorKey(tensor_name='train_loss', origin='BTest', round_number=0, report=True, tags=('metric',)),\n",
       "  array(-0.6671655, dtype=float32)),\n",
       " (TensorKey(tensor_name='val_eval', origin='BTest', round_number=0, report=True, tags=('metric',)),\n",
       "  array(0.95934121))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e2_DB_2.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whole checkpoint replacement\n",
    "from nnunet_v1 import train_nnunet\n",
    "\n",
    "# current_epoch = 1 not sure what this should be, was put as 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n",
      "done\n",
      "2024-02-22 10:45:52.939405: loading checkpoint /raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/all/model_final_checkpoint.model train= True\n",
      "Brandon DEBUG - param_lens: [98]\n",
      "\n",
      "Brandon DEBUG - saved_lens: [98]\n",
      "2024-02-22 10:45:53.378933: WARNING in loading checkpoint: self.epoch != len(self.all_tr_losses). This is due to an old bug and should only appear when you are loading old models. New models should have this fixed! self.epoch is now set to len(self.all_tr_losses)\n",
      "2024-02-22 10:45:53.387181: lr: 0.009991\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-22 10:46:00.099468: Unable to plot network architecture:\n",
      "2024-02-22 10:46:00.102669: No module named 'hiddenlayer'\n",
      "2024-02-22 10:46:00.104796: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-22 10:46:00.105384: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-22 10:46:00.109434: \n",
      "\n",
      "2024-02-22 10:46:00.243216: saving checkpoint...\n",
      "2024-02-22 10:46:00.954959: done, saving took 0.84 seconds\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# this puts starting model state in checkpoint path\n",
    "runner.replace_checkpoint(start_path)\n",
    "\n",
    "# this grabs the current epoch from that starting state (I think it is 27 - confirmed below)\n",
    "current_epoch = runner.set_tensor_dict(starting_tensor_dict)\n",
    "\n",
    "# this replaced the checkpoint again with the starting one in case the set_tensor_dict did not restore state correctly (wanting a full checkpoint replacement test here)\n",
    "runner.replace_checkpoint(start_path)\n",
    "\n",
    "# now run training to see what we get in metrics and loss etc.\n",
    "train_nnunet(epochs=1, current_epoch=current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of last training\n",
    "E2_checkpoint = torch.load(runner.checkpoint_in_path)\n",
    "\n",
    "(all_tr_losses, all_val_losses, all_val_losses_tr_mode, all_val_eval_metrics) = E2_checkpoint['plot_stuff']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'state_dict', 'optimizer_state_dict', 'lr_scheduler_state_dict', 'plot_stuff', 'best_stuff', 'amp_grad_scaler'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E2_checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NoneType,\n",
       " {'scale': 524288.0,\n",
       "  'growth_factor': 2.0,\n",
       "  'backoff_factor': 0.5,\n",
       "  'growth_interval': 2000,\n",
       "  '_growth_tracker': 1000})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(E2_checkpoint['lr_scheduler_state_dict']), E2_checkpoint['amp_grad_scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0,\n",
       " 'momentum': 0.99,\n",
       " 'dampening': 0,\n",
       " 'weight_decay': 3e-05,\n",
       " 'nesterov': True,\n",
       " 'maximize': False,\n",
       " 'foreach': None,\n",
       " 'differentiable': False,\n",
       " 'params': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E2_checkpoint['optimizer_state_dict']['param_groups'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# NEW whold file transfer test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4103565, -0.6540416, [], 0.9239635070478484)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tr_losses[-1], all_val_losses[-1], all_val_losses_tr_mode, all_val_eval_metrics[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at extra state files that may exist: I know there is a learning rate scheduler being used and maybe that is being tracked outside of the checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_stages', 'num_modalities', 'modalities', 'normalization_schemes', 'dataset_properties', 'list_of_npz_files', 'original_spacings', 'original_sizes', 'preprocessed_data_folder', 'num_classes', 'all_classes', 'base_num_features', 'use_mask_for_norm', 'keep_only_largest_region', 'min_region_size_per_class', 'min_size_per_class', 'transpose_forward', 'transpose_backward', 'data_identifier', 'plans_per_stage', 'preprocessor_name', 'conv_per_stage'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a plans.pkl file that appears to be updating when I train\n",
    "with open('/raid/edwardsb/projects/RANO/NNUnetModels/nnUNet/3d_fullres/Task542_FakePostOpp/nnUNetTrainerV2__nnUNetPlansv2.1/plans.pkl', 'rb') as _file:\n",
    "    plans = pkl.load(_file)\n",
    "plans.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans['num_stages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_01030.npz',\n",
       " '/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_51030.npz',\n",
       " '/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_61030.npz',\n",
       " '/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_71030.npz',\n",
       " '/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_81030.npz',\n",
       " '/raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_cropped_data/Task542_FakePostOpp/BraTS2021_91030.npz']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans['list_of_npz_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'batch_size': 2,\n",
       "  'num_pool_per_axis': [5, 5, 5],\n",
       "  'patch_size': array([128, 128, 128]),\n",
       "  'median_patient_size_in_voxels': array([133, 160, 136]),\n",
       "  'current_spacing': array([1., 1., 1.]),\n",
       "  'original_spacing': array([1., 1., 1.]),\n",
       "  'do_dummy_2D_data_aug': False,\n",
       "  'pool_op_kernel_sizes': [[2, 2, 2],\n",
       "   [2, 2, 2],\n",
       "   [2, 2, 2],\n",
       "   [2, 2, 2],\n",
       "   [2, 2, 2]],\n",
       "  'conv_kernel_sizes': [[3, 3, 3],\n",
       "   [3, 3, 3],\n",
       "   [3, 3, 3],\n",
       "   [3, 3, 3],\n",
       "   [3, 3, 3],\n",
       "   [3, 3, 3]]}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans['plans_per_stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstart_path\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_path' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled: True\n",
      "Brandon DEBUG - task: Task542_FakePostOpp, preprocessing_output_dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed\n",
      "\n",
      "Brandon in get_default_configuration\n",
      "\n",
      "\n",
      "Brandon - DEBUG - dataset dir: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp and plans file: /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetPlansv2.1_plans_3D.pkl\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 3d_fullres\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  4\n",
      "modalities:  {0: '0000', 1: '0001', 2: '0002', 3: '0003'}\n",
      "use_mask_for_norm OrderedDict([(0, True), (1, True), (2, True), (3, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT'), (1, 'nonCT'), (2, 'nonCT'), (3, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([133, 160, 136]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using sample dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /raid/edwardsb/projects/RANO/BraTS22_pretending_tobe_postopp/nnUNet_raw_data_base/nnUNet_preprocessed/Task542_FakePostOpp/nnUNetData_plans_v2.1\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "unpacking dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "2024-02-22 10:08:24.649935: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2024-02-22 10:08:33.072121: Unable to plot network architecture:\n",
      "2024-02-22 10:08:33.073327: No module named 'hiddenlayer'\n",
      "2024-02-22 10:08:33.074177: \n",
      "printing the network instead:\n",
      "\n",
      "2024-02-22 10:08:33.075782: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv3d(320, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (1): Conv3d(256, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (2): Conv3d(128, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (3): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    (4): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2024-02-22 10:08:33.097586: \n",
      "\n",
      "2024-02-22 10:08:33.098664: \n",
      "epoch:  0\n",
      "2024-02-22 10:16:46.139607: train loss : -0.4104\n",
      "2024-02-22 10:17:13.546043: validation loss: -0.6540\n",
      "2024-02-22 10:17:13.548350: Average global foreground Dice: [0.9042, 0.9279, 0.9398]\n",
      "2024-02-22 10:17:13.549514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edwardsb/repositories/nnUNet/nnunet/training/network_training/nnUNetTrainer.py:712: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  global_dc_per_class = [i for i in [2 * i / (2 * i + j + k) for i, j, k in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-22 10:17:13.914793: lr: 0.009991\n",
      "2024-02-22 10:17:13.915667: This epoch took 520.816386 s\n",
      "\n",
      "2024-02-22 10:17:13.990041: saving checkpoint...\n",
      "2024-02-22 10:17:14.511194: done, saving took 0.59 seconds\n",
      "--> fold == 'all'\n",
      "--> DONE\n"
     ]
    }
   ],
   "source": [
    "# Commented out, used for producing earlier checkpoint - Starting off a new model from scratch\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "\n",
    "print(f\"GPU enabled: {torch.cuda.is_available()}\")\n",
    "\n",
    "train_nnunet(epochs=1, current_epoch=0, continue_training=False)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "be-SATGOpenFL-too",
   "language": "python",
   "name": "be-satgopenfl-too"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
