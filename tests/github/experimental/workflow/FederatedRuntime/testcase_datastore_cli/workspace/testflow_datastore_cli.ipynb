{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc13070c",
   "metadata": {},
   "source": [
    "# Testcase: Datastore_cli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4394089",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857f9995",
   "metadata": {},
   "source": [
    "Initially, we start by specifying the module where cells marked with the `#| export` directive will be automatically exported. \n",
    "\n",
    "In the following cell, `#| default_exp experiment `indicates that the exported file will be named 'experiment'. This name can be modified based on user's requirement & preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from openfl.experimental.workflow.interface import FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "\n",
    "batch_size_train = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "class Bcolors:\n",
    "    HEADER = \"\\033[95m\"\n",
    "    OKBLUE = \"\\033[94m\"\n",
    "    OKCYAN = \"\\033[96m\"\n",
    "    OKGREEN = \"\\033[92m\"\n",
    "    WARNING = \"\\033[93m\"\n",
    "    FAIL = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNDERLINE = \"\\033[4m\"\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1440, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1440)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "def inference(network, test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5e31",
   "metadata": {},
   "source": [
    "Let us now define the flow of the testcase datastore cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TestFlowDatastoreAndCli(FLSpec):\n",
    "    \"\"\"\n",
    "    Testflow for Dataflow and CLI Functionality\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None, optimizer=None, rounds=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "        self.num_rounds = rounds\n",
    "        self.current_round = 0\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        print(\n",
    "            \"Testing FederatedFlow - Starting Test for Dataflow and CLI Functionality\"\n",
    "        )\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.next(\n",
    "            self.aggregated_model_validation,\n",
    "            foreach=\"collaborators\",\n",
    "            exclude=[\"private\"],\n",
    "        )\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        print(\"Performing aggregated model validation for collaborator\")\n",
    "        self.agg_validation_score = inference(self.model, self.test_loader)\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        print(\"Train the model\")\n",
    "        self.model.train()\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "        )\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                self.loss = loss.item()\n",
    "                torch.save(self.model.state_dict(), \"model.pth\")\n",
    "                torch.save(self.optimizer.state_dict(), \"optimizer.pth\")\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        self.local_validation_score = inference(self.model, self.test_loader)\n",
    "        print(\"Doing local model validation for collaborator\")\n",
    "        self.next(self.join, exclude=[\"training_completed\"])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        print(\"Executing join\")\n",
    "        self.current_round += 1\n",
    "        if self.current_round < self.num_rounds:\n",
    "            self.next(self.start)\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(\"This is the end of the flow\")\n",
    "\n",
    "        expected_flow_steps = [\n",
    "            \"start\",\n",
    "            \"aggregated_model_validation\",\n",
    "            \"train\",\n",
    "            \"local_model_validation\",\n",
    "            \"join\",\n",
    "        ]  # List to verify expected steps\n",
    "        validate_datastore_cli(\n",
    "            self, expected_flow_steps, self.num_rounds\n",
    "        )  # Function to validate datastore and cli\n",
    "\n",
    "\n",
    "def validate_datastore_cli(flow_obj, expected_flow_steps, num_rounds):\n",
    "    \"\"\"\n",
    "    This function test the flow as below\n",
    "    1. Verify datastore steps and expected steps are matching\n",
    "    2. Verify task stdout and task stderr verified through \\\n",
    "        cli is as expected\n",
    "    3. Verify no of tasks executed is aligned with the total \\\n",
    "        number of rounds and total number of collaborators\n",
    "    \"\"\"\n",
    "    validate_flow_error = []\n",
    "\n",
    "    verify_stdout = {\n",
    "        \"start\":\n",
    "            \"\\x1b[94mTesting FederatedFlow - Starting Test for Dataflow\"\n",
    "            + \" and CLI Functionality\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "        \"aggregated_model_validation\":\n",
    "            \"\\x1b[94mPerforming aggregated model validation for\"\n",
    "            + \" collaborator\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "        \"train\": \"\\x1b[94mTrain the model\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "        \"local_model_validation\":\n",
    "            \"\\x1b[94mDoing local model validation for collaborator\"\n",
    "            + \"\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "        \"join\": \"\\x1b[94mExecuting join\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "        \"end\": \"\\x1b[94mThis is the end of the flow\\x1b[0m\\x1b[94m\\n\\x1b[0m\\n\",\n",
    "    }\n",
    "\n",
    "    # fetch data from metaflow\n",
    "    from metaflow import Flow\n",
    "\n",
    "    cli_flow_obj = Flow(\"TestFlowDatastoreAndCli\")\n",
    "    cli_flow_steps = list(list(cli_flow_obj)[0])\n",
    "    cli_step_names = [step.id for step in cli_flow_steps]\n",
    "\n",
    "    steps_present_in_cli = [\n",
    "        step for step in expected_flow_steps if step in cli_step_names\n",
    "    ]\n",
    "    missing_steps_in_cli = [\n",
    "        step for step in expected_flow_steps if step not in cli_step_names\n",
    "    ]\n",
    "    extra_steps_in_cli = [\n",
    "        step for step in cli_step_names if step not in expected_flow_steps\n",
    "    ]\n",
    "\n",
    "    if len(steps_present_in_cli) != len(expected_flow_steps):\n",
    "        validate_flow_error.append(\n",
    "            f\"{Bcolors.FAIL}... Error : Number of steps fetched from \\\n",
    "                Datastore through CLI do not match the Expected steps provided {Bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    if len(missing_steps_in_cli) != 0:\n",
    "        validate_flow_error.append(\n",
    "            f\"{Bcolors.FAIL}... Error : Following steps missing from Datastore: \\\n",
    "                {missing_steps_in_cli} {Bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    if len(extra_steps_in_cli) != 0:\n",
    "        validate_flow_error.append(\n",
    "            f\"{Bcolors.FAIL}... Error : Following steps are extra in Datastore: \\\n",
    "                {extra_steps_in_cli} {Bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    for step in cli_flow_steps:\n",
    "        task_count = 0\n",
    "        func = getattr(flow_obj, step.id)\n",
    "        for task in list(step):\n",
    "            task_count = task_count + 1\n",
    "            if verify_stdout.get(step.id) != task.stdout:\n",
    "                validate_flow_error.append(\n",
    "                    f\"{Bcolors.FAIL}... Error : task stdout detected issues : \\\n",
    "                        {step} {task} {Bcolors.ENDC} \\n\"\n",
    "                )\n",
    "\n",
    "        if (\n",
    "            (func.aggregator_step)\n",
    "            and (task_count != num_rounds)\n",
    "            and (func.__name__ != \"end\")\n",
    "        ):\n",
    "            validate_flow_error.append(\n",
    "                f\"{Bcolors.FAIL}... Error : More than one execution detected \\\n",
    "                    for Aggregator Step: {step} {Bcolors.ENDC} \\n\"\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            (func.aggregator_step)\n",
    "            and (task_count != 1)\n",
    "            and (func.__name__ == \"end\")\n",
    "        ):\n",
    "            validate_flow_error.append(\n",
    "                f\"{Bcolors.FAIL}... Error : More than one execution detected \\\n",
    "                    for Aggregator Step: {step} {Bcolors.ENDC} \\n\"\n",
    "            )\n",
    "\n",
    "        if (func.collaborator_step) and (\n",
    "            task_count != len(flow_obj.collaborators) * num_rounds\n",
    "        ):\n",
    "            validate_flow_error.append(\n",
    "                f\"{Bcolors.FAIL}... Error : Incorrect number of execution \\\n",
    "                    detected for Collaborator Step: {step}. \\\n",
    "                        Expected: {num_rounds*len(flow_obj.collaborators)} \\\n",
    "                        Actual: {task_count}{Bcolors.ENDC} \\n\"\n",
    "            )\n",
    "\n",
    "    if validate_flow_error:\n",
    "        display_validate_errors(validate_flow_error)\n",
    "    else:\n",
    "        print(f\"\"\"{Bcolors.OKGREEN}\\n**** Summary of internal flow testing ****\n",
    "              No issues found and below are the tests that ran successfully\n",
    "              1. Datastore steps and expected steps are matching\n",
    "              2. Task stdout and task stderr verified through metaflow cli is as expected\n",
    "              3. Number of tasks are aligned with number of rounds and number \"\"\"\n",
    "              f\"\"\"of collaborators {Bcolors.ENDC}\"\"\")\n",
    "\n",
    "\n",
    "def display_validate_errors(validate_flow_error):\n",
    "    \"\"\"\n",
    "    Function to display error that is captured during datastore and cli test\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"{Bcolors.OKBLUE}Testing FederatedFlow - Ending test for validatng \\\n",
    "        the Datastore and Cli Testing {Bcolors.ENDC}\"\n",
    "    )\n",
    "    print(\"\".join(validate_flow_error))\n",
    "    print(f\"{Bcolors.FAIL}\\n ... Test case failed ...  {Bcolors.ENDC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5371b6d",
   "metadata": {},
   "source": [
    "## Workspace creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openfl.experimental.workflow.runtime import FederatedRuntime\n",
    "\n",
    "director_info = {\n",
    "    'director_node_fqdn':'localhost',\n",
    "    'director_port':50050,\n",
    "    'cert_chain': None,\n",
    "    'api_cert': None,\n",
    "    'api_private_key': None,\n",
    "}\n",
    "\n",
    "federated_runtime = FederatedRuntime(\n",
    "    collaborators= ['envoy_one','envoy_two'],\n",
    "    director=director_info,\n",
    "    notebook_path='./testflow_datastore_cli.ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1be87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_runtime.get_envoys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d19819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "flflow = TestFlowDatastoreAndCli(checkpoint=True)\n",
    "flflow.runtime = federated_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ec7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(flflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed_run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
