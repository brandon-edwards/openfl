{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc13070c",
   "metadata": {},
   "source": [
    "# Testcase: Internal_loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4394089",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857f9995",
   "metadata": {},
   "source": [
    "Initially, we start by specifying the module where cells marked with the `#| export` directive will be automatically exported. \n",
    "\n",
    "In the following cell, `#| default_exp experiment `indicates that the exported file will be named 'experiment'. This name can be modified based on user's requirement & preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449b5f",
   "metadata": {},
   "source": [
    "Once we have specified the name of the module, subsequent cells of the notebook need to be *appended* by the `#| export` directive as shown below. User should ensure that *all* the notebook functionality required in the Federated Learning experiment is included in this directive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openfl.experimental.workflow.interface.fl_spec import FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class bcolors:  # NOQA: N801\n",
    "    HEADER = \"\\033[95m\"\n",
    "    OKBLUE = \"\\033[94m\"\n",
    "    OKCYAN = \"\\033[96m\"\n",
    "    OKGREEN = \"\\033[92m\"\n",
    "    WARNING = \"\\033[93m\"\n",
    "    FAIL = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNDERLINE = \"\\033[4m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5e31",
   "metadata": {},
   "source": [
    "Let us now define the flow of internalloop testcase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TestFlowInternalLoop(FLSpec):\n",
    "    def __init__(self, model=None, optimizer=None, rounds= 3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.training_rounds = rounds\n",
    "        self.train_count = 0\n",
    "        self.end_count = 0\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Flow start.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f\"{bcolors.OKBLUE}Testing FederatedFlow - \"\n",
    "            + f\"Test for Internal Loops - Round: {self.train_count}\"\n",
    "            + f\" of Training Rounds: {self.training_rounds}{bcolors.ENDC}\"\n",
    "        )\n",
    "        self.model = np.zeros((10, 10, 10))  # Test model\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.next(self.agg_model_mean, foreach=\"collaborators\")\n",
    "\n",
    "    @collaborator\n",
    "    def agg_model_mean(self):\n",
    "        \"\"\"\n",
    "        Calculating the mean of the model created in start.\n",
    "        \"\"\"\n",
    "        self.agg_mean_value = np.mean(self.model)\n",
    "        print(f\"<Collab>: {self.input} Mean of Agg model: {self.agg_mean_value} \")\n",
    "        self.next(self.collab_model_update)\n",
    "\n",
    "    @collaborator\n",
    "    def collab_model_update(self):\n",
    "        \"\"\"\n",
    "        Initializing the model with random numbers.\n",
    "        \"\"\"\n",
    "        print(f\"<Collab>: {self.input} Initializing the model randomly \")\n",
    "        self.model = np.random.randint(1, len(self.input), (10, 10, 10))\n",
    "        self.next(self.local_model_mean)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_mean(self):\n",
    "        \"\"\"\n",
    "        Calculating the mean of the model created in train.\n",
    "        \"\"\"\n",
    "        self.local_mean_value = np.mean(self.model)\n",
    "        print(f\"<Collab>: {self.input} Local mean: {self.local_mean_value} \")\n",
    "        self.next(self.join)\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        \"\"\"\n",
    "        Joining inputs from collaborators\n",
    "        \"\"\"\n",
    "        self.agg_mean = sum(input.local_mean_value for input in inputs) / len(inputs)\n",
    "        print(f\"Aggregated mean : {self.agg_mean}\")\n",
    "        self.next(self.internal_loop)\n",
    "\n",
    "    @aggregator\n",
    "    def internal_loop(self):\n",
    "        \"\"\"\n",
    "        Internally Loop for training rounds\n",
    "        \"\"\"\n",
    "        self.train_count = self.train_count + 1\n",
    "        if self.training_rounds == self.train_count:\n",
    "            self.next(self.end)\n",
    "        else:\n",
    "            self.next(self.start)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        This is the 'end' step. All flows must have an 'end' step, which is the\n",
    "        last step in the flow.\n",
    "        \"\"\"\n",
    "        self.end_count += 1\n",
    "        print(\"This is the end of the flow\")\n",
    "\n",
    "        flflow = self\n",
    "        # Flow Test Begins\n",
    "        expected_flow_steps = [\n",
    "            \"join\",\n",
    "            \"internal_loop\",\n",
    "            \"agg_model_mean\",\n",
    "            \"collab_model_update\",\n",
    "            \"local_model_mean\",\n",
    "            \"start\",\n",
    "        ]  # List to verify expected steps\n",
    "        try:\n",
    "            validate_flow(\n",
    "                flflow, expected_flow_steps\n",
    "            )  # Function to validate the internal flow\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        # Flow Test Ends\n",
    "\n",
    "\n",
    "def validate_flow(flow_obj, expected_flow_steps):\n",
    "    \"\"\"\n",
    "    Validate:\n",
    "    1. If the given training round were completed\n",
    "    2. If all the steps were executed\n",
    "    3. If each collaborator step was executed\n",
    "    4. If end was executed once\n",
    "    \"\"\"\n",
    "    validate_flow_error = []  # List to capture any errors in the flow\n",
    "\n",
    "    from metaflow import Flow\n",
    "\n",
    "    cli_flow_obj = Flow(\"TestFlowInternalLoop\")  # Flow object from CLI\n",
    "    cli_flow_steps = list(cli_flow_obj.latest_run)  # Steps from CLI\n",
    "    cli_step_names = [step.id for step in cli_flow_steps]\n",
    "\n",
    "    # 1. If the given training round were completed\n",
    "    if not flow_obj.training_rounds == flow_obj.train_count:\n",
    "        validate_flow_error.append(\n",
    "            f\"{bcolors.FAIL}... Error : Number of training completed is not equal\"\n",
    "            + f\" to training rounds {bcolors.ENDC} \\n\"\n",
    "        )\n",
    "\n",
    "    for step in cli_flow_steps:\n",
    "        task_count = 0\n",
    "        func = getattr(flow_obj, step.id)\n",
    "        for task in list(step):\n",
    "            task_count = task_count + 1\n",
    "\n",
    "        # Each aggregator step should be executed for training rounds times\n",
    "        if (\n",
    "            (func.aggregator_step is True)\n",
    "            and (task_count != flow_obj.training_rounds)\n",
    "            and (step.id != \"end\")\n",
    "        ):\n",
    "            validate_flow_error.append(\n",
    "                f\"{bcolors.FAIL}... Error : More than one execution detected for \"\n",
    "                + f\"Aggregator Step: {step} {bcolors.ENDC} \\n\"\n",
    "            )\n",
    "\n",
    "        # Each collaborator step is executed for (training rounds)*(number of collaborator) times\n",
    "        if (func.collaborator_step is True) and (\n",
    "            task_count != len(flow_obj.collaborators) * flow_obj.training_rounds\n",
    "        ):\n",
    "            validate_flow_error.append(\n",
    "                f\"{bcolors.FAIL}... Error : Incorrect number of execution detected for \"\n",
    "                + f\"Collaborator Step: {step}. Expected: \"\n",
    "                + f\"{flow_obj.training_rounds*len(flow_obj.collaborators)} \"\n",
    "                + f\"Actual: {task_count}{bcolors.ENDC} \\n\"\n",
    "            )\n",
    "\n",
    "    steps_present_in_cli = [\n",
    "        step for step in expected_flow_steps if step in cli_step_names\n",
    "    ]\n",
    "    missing_steps_in_cli = [\n",
    "        step for step in expected_flow_steps if step not in cli_step_names\n",
    "    ]\n",
    "    extra_steps_in_cli = [\n",
    "        step for step in cli_step_names if step not in expected_flow_steps\n",
    "    ]\n",
    "\n",
    "    if len(steps_present_in_cli) != len(expected_flow_steps):\n",
    "        validate_flow_error.append(\n",
    "            f\"{bcolors.FAIL}... Error : Number of steps fetched from Datastore through CLI do not \"\n",
    "            + f\"match the Expected steps provided {bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    if len(missing_steps_in_cli) != 0:\n",
    "        validate_flow_error.append(\n",
    "            f\"{bcolors.FAIL}... Error : Following steps missing from Datastore: \"\n",
    "            + f\"{missing_steps_in_cli} {bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    if len(extra_steps_in_cli) != 0:\n",
    "        validate_flow_error.append(\n",
    "            f\"{bcolors.FAIL}... Error : Following steps are extra in Datastore: \"\n",
    "            + f\"{extra_steps_in_cli} {bcolors.ENDC}  \\n\"\n",
    "        )\n",
    "\n",
    "    if not flow_obj.end_count == 1:\n",
    "        validate_flow_error.append(\n",
    "            f\"{bcolors.FAIL}... Error : End function called more than one time...{bcolors.ENDC}\"\n",
    "        )\n",
    "\n",
    "    if validate_flow_error:\n",
    "        display_validate_errors(validate_flow_error)\n",
    "        raise Exception(f\"{bcolors.FAIL}Test for Internal Loop FAILED\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"\"\"{bcolors.OKGREEN}\\n **** Summary of internal flow testing ****\n",
    "        No issues found and below are the tests that ran successfully\n",
    "        1. Number of training completed is equal to training rounds\n",
    "        2. Cli steps and Expected steps are matching\n",
    "        3. Number of tasks are aligned with number of rounds and number of collaborators\n",
    "        4. End function executed one time {bcolors.ENDC}\"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "def display_validate_errors(validate_flow_error):\n",
    "    \"\"\"\n",
    "    Function to display error that is captured during flow test\n",
    "    \"\"\"\n",
    "    print(\"\".join(validate_flow_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openfl.experimental.workflow.runtime import FederatedRuntime\n",
    "\n",
    "director_info = {\n",
    "    'director_node_fqdn':'localhost',\n",
    "    'director_port':50050,\n",
    "    'cert_chain': None,\n",
    "    'api_cert': None,\n",
    "    'api_private_key': None,\n",
    "}\n",
    "\n",
    "federated_runtime = FederatedRuntime(\n",
    "    collaborators= ['envoy_one','envoy_two'],\n",
    "    director=director_info, \n",
    "    notebook_path='./testflow_internal_loop.ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1be87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_runtime.get_envoys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d19819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "flflow = TestFlowInternalLoop(checkpoint=True)\n",
    "flflow.runtime = federated_runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ec7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(flflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed_run",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
